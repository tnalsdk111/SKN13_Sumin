








%pip install  beautifulsoup4  lxml








from bs4 import BeautifulSoup

with open("example.html", "rt", encoding='utf-8') as fr:
    html_doc = fr.read()
    
print(html_doc[:50])
# print(type(html_doc))


soup = BeautifulSoup(html_doc, "lxml")


print(soup.prettify())











from bs4 import BeautifulSoup

with open("example.html", "rt", encoding="utf-8") as fr:
    html_doc = fr.read()

soup = BeautifulSoup(html_doc, "lxml")


result = soup.find_all("div")


print(len(result))
result


tag1 = result[0]
print("content:", tag1.text, tag1.get_text())
print("class속성값:", tag1.get("class"), tag1['class'])


result = soup.find("div")
print(type(result))
print("-"*50)
print(result)


# 태그의 content와 attribute 조회

print("content text:", result.text)
# print("content text:", result.get_text())
# print("attribue의 value:", result.get("class"))
# print("attribue의 value:", result["class"])


# 태그의 모든 자식 요소들 조회
result.contents


from pprint import pprint

result = soup.find_all("a") 
# result = soup.find_all(["a", "span"])  #한번에 여러이름의 태그드을 조회.
# result = soup.find_all("div", attrs={"class":"name"}) # 태그이름 + 속성
# result = soup.find_all("div", attrs={"class":"animal_info", "id":"animal1"}) # 속성 조건이 여러개
# result = soup.find_all("a", attrs={"href":"https://www.coexaqua.com"})

# import re
# result = soup.find_all("a", attrs={"href":re.compile(r".com$")}) # 정규표현식-.com으로 끝나는.

pprint(result)


result_list = []
for tag in result:
    print(tag.text, tag['href'])
    result_list.append([tag.text, tag['href']]) # list[text, href]



result_list





from bs4 import BeautifulSoup

with open("example.html", "rt", encoding="utf-8") as fr:
    html_doc = fr.read()

soup = BeautifulSoup(html_doc, "lxml")



# css selector를 이용한 조회

result = soup.select("a")         #  태그이름(a)  
# result = soup.select("a, span") # 태그이름(여러개)
# result = soup.select("ul a")    # ul의 자손인 a태그 찾는다.

# result = soup.select_one("#animal1")             # 모든 태그중 id=animal1
# result = soup.select("ul + div")                 # ul의 다음 형제 태그중 div
# result = soup.select("body > div:nth-child(3)")  # body의 3번째 자식 div

# result = soup.select("a[href]")                        # href 속성이 있는 a 태그들
# result = soup.select("a[href='http://www.naver.com']") # href='http://www.naver.com' 속성을 가진 a 그그
# result = soup.select('a[href$=".do"]')                 # $=  href 속성값이 .do로 끝나는 a태그들
# result = soup.select('a[href^="https"]')               # =^  href 속성값이 https로 시작하는 a태그

pprint(result)


for tag in result:
    print(tag.text, tag['href'], tag.name)



