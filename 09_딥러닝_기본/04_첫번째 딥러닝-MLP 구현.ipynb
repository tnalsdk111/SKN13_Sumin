{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pytorch 개발 Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. **데이터 준비**\n",
    "    - Dataset 준비\n",
    "    - Dataloader 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. **입력과 출력을 연결하는 Layer(층)으로 이뤄진 네트워크(모델)을 정의**\n",
    "    - **Sequential 방식**: 순서대로 쌓아올린 네트워크로 이뤄진 모델을 생성하는 방식\n",
    "        - layer를 순서대로 쌓은 모델을 구현할때 간단히 모델을 정의할 수 있다.\n",
    "        - layer block을 정의하는데 사용할 수 있다.\n",
    "    - **Subclass 방식**: 네트워크를 정의하는 클래스를 구현.\n",
    "        - 다양한 구조의 모델을 정의할 수 있다.\n",
    "        - inializer에서 필요한 layer들을 생성한다.\n",
    "        - forward(self, X) 메소드에 forward propagation 계산을 구현한다.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. **train**\n",
    "    - train 함수, test 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4. test set 최종평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MNIST 이미지 분류 \n",
    "- **[MNIST](https://ko.wikipedia.org/wiki/MNIST_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4) (Modified National Institute of Standards and Technology) database**\n",
    "- 흑백 손글씨 숫자 0-9까지 10개의 범주로 구분해놓은 데이터셋\n",
    "- 하나의 이미지는 28 * 28 pixel 의 크기\n",
    "- 6만개의 Train 이미지와 1만개의 Test 이미지로 구성됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # 다양한 layer/모델 들이 정의된 패키지. (Neural Network)\n",
    "from torch.utils.data import DataLoader # DataLoader 클래스 -> 모델에 데이터들을 제공하는 역할.\n",
    "from torchvision import datasets, transforms \n",
    "# torchvision 패키지(라이브러리): pytorch의 영상상 전용 sub package\n",
    "## datasets(모듈): Vision(영상)관련 공개개 데이터셋들을 제공하는 모듈\n",
    "## transforms: 영상 데이터 전처리 기능들을 제공하는 모듈\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### device 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어느 Device에서 연산처리를 할지 지정. (cpu, cuda(GPU))\n",
    "# device = \"cpu\"\n",
    "print(torch.cuda.is_available())  # cuda를 사용할 수있는 환경인지 조회\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # 2.0이전: torch.Device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAC OS  (\"cpu\", \"mps\")\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터, 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001 # 학습률. 0 ~ 1 실수. \n",
    "batch_size = 256  # 모델이 학습할 때 한 번에 몇 개씩 모델에 제공할지 개수. \n",
    "epochs = 20\n",
    "# step: 모델의 파라미터들을 update하는 단위.\n",
    "#  - 1 step: batch_size(256)개수의 데이터로 파라미터를 한번 update한 것.\n",
    "# epoch: train set 전체를 학습하는 단위. \n",
    "#  - 1 epoch: 전체 데이터를 한번 다 학습한 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 학습이 끝난 모델을 저장할 디렉토리.\n",
    "model_dir = \"models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "# Dataset을 저장할 디렉토리\n",
    "dataset_dir = \"datasets/mnist\"\n",
    "os.makedirs(dataset_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T05:02:52.852140Z",
     "start_time": "2021-08-30T05:02:52.563117Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MNIST dataset Loading\n",
    "\n",
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST(\n",
    "    root=dataset_dir, # Dataset을 읽어올 디렉토리.\n",
    "    download=True,    # root 에 dataset이 없을 경우 다운로드 받을지 여부.\n",
    "    # transform=transforms.ToTensor()\n",
    ")\n",
    "testset = datasets.MNIST(\n",
    "    root=dataset_dir,\n",
    "    download=True,\n",
    "    train=False,       # Trainset인지 여부. True(default): train set, False: test set\n",
    "    # transform=transforms.ToTensor()\n",
    ")\n",
    "######################################################################################\n",
    "#  transform=함수 -> input data를 전처리하는 함수를 전달.\n",
    "######################################################################################\n",
    "# transforms.ToTensor 가 하는 처리\n",
    "## ndarray, PIL.Image 객체를 torch.Tensor 로 변환.\n",
    "## (height, width, channel) 순서를 channel first (channel, height, width) 형태로 변환.\n",
    "## pixcel값들(0~255 정수)을 0 ~ 1 로 정규화. (Feature Scaling - MinMaxScaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별데이터 조회\n",
    "trainset[0]  # tuple: (input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array(trainset[0][0])  # PIL.Image -변환-> ndarray\n",
    "print(a.shape, a.dtype)\n",
    "a.min(), a.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ transforms.ToTensor() 적용 후 확인################\n",
    "f1 = trainset[0][0]\n",
    "print(f1.shape)  # (1:channel-grayscale, 28: height, 28:width)\n",
    "print(f1.dtype, f1.type())\n",
    "print(f1.min(), f1.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "print(len(trainset))\n",
    "idx = random.randint(0, len(trainset)) #0 ~ 60000 사이 랜덤 정수를 반환.\n",
    "img, label = trainset[idx]\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\") # (1, 28, 28) -> (28, 28). matplotlib은 이미지를 (h, w, c) 로 전달해야함.\n",
    "plt.title(f\"{idx}\\n{label}\")\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader: Dataset의 데이터들을 모델에 제공하는 역할. 데이터들을 모델에 어떻게 제공할지 설정해서 생성.\n",
    "# Dataset: 데이터들을 가지고 있는 역할. 하나씩 조회하는 기능을 제공.\n",
    "train_loader = DataLoader(\n",
    "    trainset,              # Dataset\n",
    "    batch_size=batch_size, # batch size (256)\n",
    "    shuffle=True,   # 모델에 데이터를 제공하기 전에 섞을지 여부. (default: False) True: 한 epoch 학습 전에 섞는다.\n",
    "    drop_last=True, # 모델에 제공할 데이터의 개수가 batch_size보다 적으면 제공하지 않는다. (학습에 사용안함)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(testset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 개수.\n",
    "len(trainset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 epoch 당 step 수 조회회.\n",
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subclass(상속) 방식\n",
    "## - nn.Module 상속한 클래스를 정의.\n",
    "## - __init__(): 입력값을 추론(순전파 연산)하는데 필요한 layer객체들을 생성.\n",
    "## - forward(): __init__() 에서 생성한 layer들을 이용해 연산 로직을 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # 상위클래스 nn.Module 을 초기화.\n",
    "        \n",
    "        # Linear(input feature 개수, output feature 개수)\n",
    "        self.lr1 = nn.Linear(784, 128) # (784:(28*28): MNIST 이미지의 pixcel수, 출력: 128)\n",
    "        self.lr2 = nn.Linear(128, 64)  # (128: lr1의 출력개수, 출력: 64)\n",
    "        self.lr3 = nn.Linear(64, 32)   # (64:  lr2의 출력개수, 출력: 32)\n",
    "        self.lr4 = nn.Linear(32, 10)   # (32:  lr3의 출력개수, 출력: 10)\n",
    "        # 마지막 Linear()의 출력 개수(10) - 분류할 class개수(0 ~ 9)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        X를 입력 받아서 y를 추론하는 계산로직을 정의\n",
    "        initializer에서 정의한 Linear들을 이용해서 계산.\n",
    "        Args:\n",
    "            X(torch.FloatTensor) - 추론할 MNIST 이미지들. shape: (batch_size, 1, 28, 28)\n",
    "        \"\"\"\n",
    "        # (batch_size, 1, 28, 28) 를 (batch_size, 784) feature들을 1차원으로 변환.\n",
    "        X = torch.flatten(X, start_dim=1) # 다차원 배열을 1차원 배열로 변환. (start_dim=1, Flatten 시킬 시작 axis지정. 0축은 놔두고 1축 부터 flatten시킨다.)\n",
    "        X = self.lr1(X)  # Linear: 선형함수\n",
    "        X = nn.ReLU()(X) # Activation(활성) 함수. 비선형함수. ReLU(x): max(x, 0)\n",
    "        \n",
    "        X = self.lr2(X)\n",
    "        X = nn.ReLU()(X)\n",
    "        \n",
    "        X = self.lr3(X)\n",
    "        X = nn.ReLU()(X)\n",
    "        \n",
    "        output = self.lr4(X)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델, loss function, optimizer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델객체 생성\n",
    "model = MNISTModel()\n",
    "# 확인\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss함수 - 학습 할 때 모델이 예측한 값과 정답간의 오차를 계산하는 함수. 이 오차를 줄이는 방향으로 파라미터를 변경한다.\n",
    "# 다중 분류 문제의 Loss함수: crossentropyloss함수. (이진분류: binary crossentropy, 회귀: mse)\n",
    "loss_fn = nn.CrossEntropyLoss()  # torch.nn.functional.cross_entropy 함수사용도 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer 정의: 모델의 파라미터들을 업데이트하고 파라미터들의 gradient값을 초기화 한다.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습(훈련-train) 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습시 계산에 사용되는 값들은 같은 device(cpu or cuda or mps)에 있어야 한다\n",
    "## device로 이동할 대상: Model객체, X(input), y(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# 학습\n",
    "## 에폭별 검증결과들을 저장할 리스트\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "valid_acc_list = []\n",
    "s = time.time()\n",
    "\n",
    "# 학습-중첩 반복문: epoch 반복 -> step(batch_size) 에 대한 반복\n",
    "for epoch in range(epochs):\n",
    "    ###############################################\n",
    "    # 모델 Train - 1 epoch : Trainset\n",
    "    ###############################################\n",
    "    model.train()  # 모델을 train 모드로 변환.\n",
    "    train_loss = 0 # 현재 epoch의 train loss를 저장할 변수.\n",
    "\n",
    "    # batch 단위로 학습: 1 step - 1개 batch의 데이터로 학습.\n",
    "    for X_train, y_train  in train_loader: # 한번 반복할 때마다 1개 batch 데이터를 순서대로 제공. (X, y) 를 묶어서 제공한다.\n",
    "        # 1. X, y를 devcie로 이동\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        # 2. 모델을 이용해 추론\n",
    "        pred = model(X_train) # Model.forward(X_train) 메소드 호출\n",
    "        # 3. loss 계산\n",
    "        loss = loss_fn(pred, y_train)\n",
    "        # 4. gradient 계산\n",
    "        loss.backward()\n",
    "        # 5. 모델의 파라미터들(weight, bias) update\n",
    "        optimizer.step()\n",
    "        # 6. gradient 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 학습 결과 저장및 출력을 위해 loss 저장.\n",
    "        train_loss = train_loss + loss.item() \n",
    "\n",
    "    \n",
    "    train_loss = train_loss / len(train_loader)  # 한 에폭에서 학습한 step별 loss의 평균계산.\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    ###############################################\n",
    "    # 1 epoch 학습한 결과 검증: Testset\n",
    "    ###############################################\n",
    "    model.eval()  # 모델을 evaluation() (추론, 검증) 모드로 변환.\n",
    "    valid_loss = 0\n",
    "    valid_acc = 0\n",
    "    with torch.no_grad(): # 추론만 함 -> gradient 계산할 필요 없음. -> grad_fn 구할 필요없다.\n",
    "        for X_valid, y_valid in test_loader:\n",
    "            # 1. device 로 이동\n",
    "            X_valid, y_valid = X_valid.to(device), y_valid.to(device)\n",
    "            # 2. 추론\n",
    "            pred_valid = model(X_valid)\n",
    "            # 3-1. 검증 -> loss 계산\n",
    "            valid_loss = valid_loss + loss_fn(pred_valid, y_valid).item()\n",
    "            # 3-2. 검증 -> accuracy 계산\n",
    "            ## pred_valid shape: (256, 10: class별 확률) -> 정답 class 추출\n",
    "            pred_valid_class = pred_valid.argmax(dim=-1)\n",
    "            valid_acc = valid_acc + torch.sum(y_valid == pred_valid_class).item()\n",
    "        \n",
    "        # 검증결과 누적값의 평균\n",
    "        valid_loss = valid_loss / len(test_loader)  # loss는 step수 나눔.\n",
    "        valid_acc = valid_acc / len(testset)        # accuracy는 데이터 개수로 나눔.\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        valid_acc_list.append(valid_acc)\n",
    "\n",
    "        # 검증 결과 출력\n",
    "        print(f\"[{epoch+1:02d}/{epochs}] train_loss: {train_loss}, valid_loss: {valid_loss}, valid_acc: {valid_acc}\")\n",
    "\n",
    "e = time.time()\n",
    "print('학습에 걸린 시간(초):', e-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 로그 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loss, valid loss, valid acc 를 epoch 별로 어떻게 변하는지 시각화.\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs+1), train_loss_list, label=\"train loss\")\n",
    "plt.plot(range(1, epochs+1), valid_loss_list, label=\"valid loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\":\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs+1), valid_acc_list)\n",
    "plt.title(\"valid accuracy\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(True, linestyle=\":\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습된 모델 저장 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "saved_dir = \"models\"\n",
    "os.makedirs(saved_dir, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(saved_dir, \"mnist_model.pt\")\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장: 파일 확장자 - pt, pth\n",
    "torch.save(model, save_path)  #  (저장할 모델, 저장할 파일 경로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 저장된 모델 load(불러오기)\n",
    "load_model = torch.load(save_path)\n",
    "print(load_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 성능 최종 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = load_model.to(device)\n",
    "load_model.eval() # 평가모드\n",
    "\n",
    "test_loss = test_acc = 0\n",
    "with torch.no_grad():\n",
    "    for X_test, y_test in test_loader:\n",
    "        # device 이동\n",
    "        X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "        # 추론\n",
    "        pred_test = load_model(X_test)\n",
    "        # 검증 - loss\n",
    "        loss_test = loss_fn(pred_test, y_test)\n",
    "        test_loss += loss_test.item()\n",
    "        # 검증 - accuracy\n",
    "        ## class\n",
    "        pred_test_class = pred_test.argmax(dim=-1)\n",
    "        test_acc += torch.sum(pred_test_class == y_test).item()\n",
    "\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_acc = test_acc / len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = load_model(X_test)\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_class = p.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(y_test == p_class).item() # 맞은 것의 개수."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 새로운 데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_data(device=\"cpu\", *path):\n",
    "    \"\"\"\n",
    "    받은 경로의 이미지들을 읽어서 Tensor로 변환해 반환한다.\n",
    "\n",
    "    1. 전달받은 경로의 이미지 파일들을 읽는다.\n",
    "    2. 28 x 28 로 resize\n",
    "    3. torch.Tensor로 변환 + 전처리\n",
    "    4. devcie로 이동시킨 뒤 반환한다다.\n",
    "    \"\"\"\n",
    "    input_tensors = []\n",
    "    for p in path:\n",
    "        img = Image.open(p)\n",
    "        img = img.convert('L')     # grayscale로 변환.\n",
    "        img = img.resize((28, 28)) # 모델이 학습한 데이터 size(28, 28)로 변환.\n",
    "        img = transforms.ToTensor()(img)\n",
    "        input_tensors.append(img)\n",
    "        \n",
    "    return torch.stack(input_tensors).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, inputs, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    받은 model에 inputs를 추론하여 그 결과 class들을 반환한다.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        pred = model(inputs)\n",
    "        pred_class = pred.argmax(dim=-1)\n",
    "        return pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob을 이용해 테스트 이미지들의 경로 조회.\n",
    "from glob import glob\n",
    "file_list = glob(\"test_img/**/*.png\")\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = load_data(device, *file_list)\n",
    "result_pred = predict(load_model, r)\n",
    "result_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확인\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for idx, (path, label) in enumerate(zip(file_list, result_pred)):\n",
    "    # print(idx, path, label, sep=\" , \")\n",
    "    img = Image.open(path).convert('L')\n",
    "    plt.subplot(3, 5, idx+1)  #3, 4\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(f\"예측결과: {label}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "347.844px",
    "left": "1891px",
    "right": "20px",
    "top": "361px",
    "width": "486px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
