{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM 개요\n",
    "\n",
    "- 대형 언어 모델(LLM, Large Language Model)은 **자연어 처리(NLP)** 분야에서 혁신을 이끌고 있는 **딥러닝 기반의 AI 모델**이다.\n",
    "- 대부분의 LLM은 **트랜스포머(Transformer)** 아키텍처에 기반해 설계 되었으며 Layer를 깊게 쌓아 아주 큰 구조를 가지고 있다. \n",
    "- LLM은 방대한 양의 텍스트 데이터를 학습하여 인간의 언어를 이해하고 생성하는 능력을 있다.\n",
    "- 다양한 분야의 대량의 데이터로 학습했기 때문에 특정 분야에 국한되지 않고 다양한 작업에 바로 사용할 수있다.\n",
    "\n",
    "![llm_history.png](figures/llm_history.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM의 주요 특징\n",
    "\n",
    "- **대규모 모델로 대규모 데이터 학습**\n",
    "    - LLM은 두가지 측면에서 대규모(Large)이다.\n",
    "        - 모델의 크기\n",
    "            - LLM은 수십억에서 수조 개에 이르는 매개변수를 보유하고 있다.\n",
    "        - 훈련 데이터셋\n",
    "            - GPT-3 는 4990억 토큰의 데이터셋을 학습함. (보통 1토큰이 대략 영문 4글자 정도됨.)\n",
    "    - 일반적으로 **70억(7B)개** 이상의 파라미터를 가진 모델이 LLM으로 간주되며, 대표적으로 **GPT-3.5**는 **1750억(175B)** 개의 파라미터를 갖고 있다.\n",
    "    - 이러한 대규모 학습 덕분에 문맥을 이해하고 연관된 문장을 예측하는 성능이 높아진다.\n",
    "- **자연어 생성**\n",
    "    - LLM은 프롬프트에 기반해 자연스럽고 맥락을 고려한 언어를 생성할 수 있다.\n",
    "    - 특정 분야에 국한되지 않고 다양한 작업에 적용 가능하여 범용성이 좋다. \n",
    "    - 이는 **챗봇, 자동 텍스트 생성, 요약, 번역** 등 다양한 응용 분야에서 활발히 활용되며, 창작과 데이터 분석의 도구로도 점점 널리 사용되고 있다.\n",
    "    - 예) 질문에 대한 답변 생성, 스토리텔링, 정보 요약 등 다양한 형태의 텍스트 응답 생성이 가능하다.\n",
    "- **다국어 지원**\n",
    "    - LLM은 다양한 언어로 학습되며, 이를 통해 **언어 간 번역** 및 **다국어 텍스트 처리**에서도 우수한 성능을 보인다.\n",
    "    - 이와 같이 여러 언어를 지원하는 모델을 **Multilingual Model**이라고 한다.\n",
    "    - 다국어 지원을 통해 다양한 국가의 사용자에게 폭넓은 접근성을 제공하며, 언어 장벽을 줄이는 데 기여한다.\n",
    "- **파운데이션 모델**\n",
    "    - LLM 모델은 범용적인 특징을 가지며, 다양한 분야에 적용할 수 있도록 설계되어 있다. 이는 대규모 데이터를 활용해 학습된 모델이기 때문이다.\n",
    "    - 이런 범용적인 특징으로 LLM을 파운데이션(기반) 모델이라고 한다.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM의 한계\n",
    "\n",
    "- **편향(Bias) 문제**\n",
    "    - LLM은 학습한 텍스트 데이터에 포함된 편향된 정보를 반영할 수 있어, **차별적 표현**이나 **정치적 편향**을 포함한 출력을 생성할 위험이 있다.\n",
    "    - 이 문제를 해결하기 위해 **편향 감지**와 **보정 알고리즘**에 대한 연구가 활발히 진행 중이다.\n",
    "- **잘못된 정보 생성 (할루시네이션)**\n",
    "    - LLM은 **정확한 정보를 제공하는 목적으로 학습한 모델이 아니**라 언어의 특징(문법, 구문, 의미적 관계 등)을 학습한 모델이다.\n",
    "    - 따라서 LLM이 질문에 대해 실제로 존재하지 않는 정보를 그럴 듯하게 생성하거나, 잘못된 출처를 기반으로 한 답변을 생성할 수가 있다.\n",
    "    - 이런 현상을 **할루시네이션(Hallucination)** 이라고 한다.\n",
    "- **높은 에너지 소비**\n",
    "    - LLM은 학습 및 실행에 막대한 컴퓨팅 자원과 전력을 필요로 하며, 이는 환경적 비용을 초래할 수 있다.\n",
    "    - 예) **GPT-3**의 훈련에는 **약 1287 MWh**의 에너지가 소모되었다. 이는 전기차 대략 21000대를 충전할 수있는 양이다.\n",
    "- **프라이버시 및 보안 이슈**\n",
    "    - LLM이 다양한 공공 데이터로 학습되는 만큼, 민감한 정보가 노출될 가능성이 존재한다.\n",
    "    - **데이터 보호**와 **프라이버시 강화**를 위한 기술이 필요하며, 민감한 정보를 학습하지 않도록 하는 규제 방안도 연구되고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Source LLM과 Closed Source LLM\n",
    "\n",
    "### 1. 개념\n",
    "\n",
    "- **Open Sourc LLM**\n",
    "    - 소스 코드와 모델 가중치가 공개되어 누구나 접근, 수정, 배포할 수 있는 대규모 언어 모델.\n",
    "    - 연구자, 개발자, 기업 등이 자유롭게 활용하고 커스터마이징 가능.\n",
    "- **Closed Source LLM**\n",
    "    -  소스 코드와 모델 가중치가 비공개되어 특정 기업이나 기관만이 접근 및 활용할 수 있는 대규모 언어 모델.\n",
    "    -  일반 사용자나 개발자는 API 등을 통해 제한적으로 기능을 이용할 수 있음.\n",
    " \n",
    "### 2. 종류\n",
    "\n",
    "- **Open Sourc LLM**:\n",
    "  - **LLaMA 시리즈**: Meta에서 개발한 모델로, LLaMA 3.2 버전까지 발표되었다.\n",
    "  - **Solar**: 업스테이지에서 개발한 LLM.\n",
    "  - **Mistral 7B, Mistral Large2**: 프랑스 Mistral AI 에서 개발한 모델.  \n",
    "  - **Falcon 시리즈**: 아부다비의 Technology Innovation Institute에서 개발한 모델. \n",
    "- **Closed Source LLM**:\n",
    "  - **GPT 시리즈**: OpenAI에서 개발한 모델로, GPT-3, GPT-4 등이 있음.\n",
    "  - **Claude**: Anthropic에서 개발한 모델.\n",
    "  - **Gemini**: Google DeepMind에서 개발한 모델.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsDT-Nk_RN7x"
   },
   "source": [
    "# [LangChain](https://python.langchain.com/docs/introduction/)\n",
    "![langchain_logo.png](figures/langchain_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmCWeRwTyZu6"
   },
   "source": [
    "## Langchain 개요\n",
    "- LangChain은 대규모 언어 모델(LLM)을 기반으로 어플리케이션을 구축하기 위한 오픈 소스 프레임워크이다.\n",
    "- LLM을 활용한 어플리케션과 그 파이프라인을 빠르게 구현할 수있는 플랫폼 개발을 위해 2022년 해리슨 체이스(Harrison Chase)이 오픈소스로 시작했으며 2024년 1월 최초의 안정화 버전인 v0.1이 발표되었다.\n",
    "- 2024년 11월 현재 v0.3 이 발표되었으며 LLM 생태계 변화에 맞춰 빠르게 발전하고 있다.\n",
    "- 다양한 LLM 모델을 추상화 하여 동일한 interface로 각 LLM 들을 사용할 수있으며 LLM 을 이용한 다양한 서비스들을 쉽게 구축할 수있도록 지원하고 있다.\n",
    "\n",
    "![langchain_intro.png](figures/langchain_intro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e87-Y8L4xlE0"
   },
   "source": [
    "## LangChain의 주요 장점\n",
    "\n",
    "1. **체인 구조를 통한 기능 확장**\n",
    "   - 여러 기능 모듈을 체인으로 연결하여 복잡한 워크플로 구성이 가능.\n",
    "   - 다양한 작업을 자동화하고, 확장성을 극대화할 수 있음.\n",
    "   - 예: 텍스트 생성 → 데이터베이스 조회 → 결과 요약 등의 다단계 작업을 손쉽게 처리.\n",
    "\n",
    "2. **다양한 LLM 연동 지원**\n",
    "   - OpenAI, Hugging Face, Antrophic 등 다양한 대형 언어 모델을 선택적으로 연동 가능.\n",
    "   - 프로젝트 요구에 따라 최적화된 모델 사용 가능.\n",
    "\n",
    "3. **에이전트(Agents) 기능 지원**\n",
    "   - 외부 도구(API, 계산기, 데이터베이스 등)와의 연동을 통해 복잡한 작업을 자동으로 수행.\n",
    "   - LangGraph를 이용하면 agent 개발을 쉽게 할 수있다.\n",
    "   - 언어 모델의 한계를 넘어서 다양한 실용적인 작업 처리 가능.\n",
    "\n",
    "4. **새로운 데이터 활용 가능**\n",
    "   - 학습된 데이터 외에 사용자로부터 입력된 새로운 데이터를 실시간으로 처리하여 반영 가능. (RAG)\n",
    "   - 유연한 데이터 활용을 통해 맞춤형 결과 생성 가능하며 LLM이 학습하지 않은 최신데이터를 반영할 수있고 이를 통해 할루시네이션을 최소화할 수있다.\n",
    "\n",
    "5. **프롬프트 관리의 용이성**\n",
    "   - 프롬프트 템플릿 기능을 제공해 프롬프트 작성, 재사용, 유지보수가 편리함.\n",
    "   - Langchain-Hub 를 통해 사용자들이 작성한 프롬프트 템플릿을 공유할 수있다.\n",
    "\n",
    "6. **데이터 연결 기능**\n",
    "   - SQL, NoSQL 데이터베이스 및 파일 저장소와의 통합 지원.\n",
    "\n",
    "7. **라이브러리 추상화 및 편리한 구현**\n",
    "   - 파이썬, 자바스크립트 라이브러리를 제공한다.\n",
    "   - 주요 기능들이 잘 추상화(wrapped)되어 있어 구현이 쉬움.\n",
    "   - **핵심 장점**: 빠른 개발과 간단한 프로토타이핑 가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljVRedt-lc2z"
   },
   "source": [
    "# LangChain 주요 모듈\n",
    "- LangChain은 LLM 기반 Application개발을 위한 다양한 모듈을 제공한다.\n",
    "\n",
    "![langchain_modules.png](figures/langchain_modules.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkIlTy9Z0dei"
   },
   "source": [
    "## Model I/O\n",
    "- LLM 입력할 프롬프트 작성과(Input), LLM 출력결과(Output)를 원하는 형태으로 변환하는 모듈\n",
    "  - `Prompt`: LLM에게 특정 작업을 수행하도록 지시하거나 정보를 요청하는 입력 텍스트를 말한다. Langchain은 프롬프트 템플릿화, 동적으로 선택,  관리를 지원한다.\n",
    "  - `Output Parser`: LLM이 응답한 출력결과에서 필요한 정보를 추출하거나 필요한 형식으로 변환한다.\n",
    "\n",
    "![langchain_model_io.png](figures/langchain_model_io.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvM32MFK1DcT"
   },
   "source": [
    "## Data Connection\n",
    "- text, pdf 등의 외부 파일이나 database와 연결해 외부 데이터를 읽어와 프롬프트에 추가해 LLM에게 요청할 수있다.\n",
    "- 이런 방식으로 LLM이 학습하지 않은 정보에 대한 응답을 받을 수있다.\n",
    "- 이 작업을 위해 Vector DB가 이용되며 이런 일련의 작업을 RAG(Retrieval Augmented Generation - 검색 증강 생성) 이라고 한다.\n",
    "\n",
    "![langchain_dataconnection.png](figures/langchain_dataconnection.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDesq1jXldGm"
   },
   "source": [
    "## Chains\n",
    "\n",
    "- Chain은 하나의 task를 수행하기 위해 연결되는 작업들을 파이프라인으로 묶어 주는 것으로 Langchain의 핵심 기능 중 하나이다.\n",
    "- 예) LLM에게 받은 한국어 응답을 다시 LLM에게 요약 요청을 하고 그것을 다시 LLM 에게 영어로 번역요청을 한다.  이런 일련의 작업을 묶어서 한번의 요청으로 실행될 수있게 한다.\n",
    "- Langchain은 Chain 을 위해 LCEL(LangChain Expression Language) 라는 표현식을 제공한다.\n",
    "\n",
    "![langchain_chain.png](figures/langchain_chain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o53nIRaQoB3A"
   },
   "source": [
    "## Agents\n",
    "\n",
    "- 작업을 수행하기 위한 다양한 기능(tool)들을 준비하고 하고 사용자의 요청을 받으면 LLM 이 작업을 수행하기 위한 적당한 tool들을 선택해 처리하도록 하는 기법으로 Chain과 함께 Langchain의 중요한 모듈 중 하나다.\n",
    "- Langchain에 다양한 tool들이 제공되고 있고 개발자가 필요한 tool들을 만들 수도 있다.\n",
    "- 기본적인 작업들이 text를 이용한 LLM과의 상호 작용이었다면, agent는 외부 다른 리소스와 상호작용이 가능할 수 있게 해준다.\n",
    "\n",
    "![langchain_agent](figures/langchain_agent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igfPIVUkoB6W"
   },
   "source": [
    "## Memory\n",
    "- LLM은 상태 비저장형이지만 정확한 응답을 위해서는 이전 대화내용(context)를 저장해야 할 수있다.\n",
    "- Langchain의 메모리 모듈을 이용하면 이런 작업을 도와준다.\n",
    "- 컴퓨터에 메모리에 대화내용을 저장하여 대화 도중의 context를 기억하거나 database를 이용해 영구적로 저장할 수도 있다.\n",
    "\n",
    "![langchain_memory.png](figures/langchain_memory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ba6X6-XldK1"
   },
   "source": [
    "## Callbacks\n",
    "- Langchain 은 작업 수행 도중 실행할 수있는 다양한 콜백 시스템을 제공한다.\n",
    "- Callback을 이용해 로깅, 모니터링, 스트리밍 같은 작업들을 할 수있다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNJV84aoVUs1hiRJlGVECZ6",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
