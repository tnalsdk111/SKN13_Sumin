{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f1283a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cff5b412-7083-4729-b85e-203069873ce7",
   "metadata": {},
   "source": [
    "# Chroma Vector Database\n",
    "- Chroma는 대규모 언어 모델(LLM) 애플리케이션 구축을 위해 설계된 AI 네이티브 **오픈 소스 벡터 데이터베이스**다.    \n",
    "- 임베딩 저장소, 쿼리 및 검색 등의 핵심 기능을 제공하여 개발자들이 효율적으로 작업할 수 있도록 돕는다. \n",
    "- https://www.trychroma.com/\n",
    "  \n",
    "## Chroma의 주요 특징\n",
    "\n",
    "- **오픈 소스 라이선스** \n",
    "  - Apache 2.0 라이선스에 따라 제공되어 누구나 자유롭게 사용하고 수정할 수 있다. \n",
    "- **다양한 개발 환경 지원**\n",
    "  -  Python 및 JavaScript/TypeScript SDK를 지원하여 다양한 Langchain 과 연동하여 활용할 수 있다. \n",
    "- **유연한 데이터 저장 옵션**\n",
    "  -  HTTP 방식, 디스크 저장 방식, 인메모리 방식을 선택하여 데이터를 저장할 수 있어 사용자 입장에서 매우 편리하다. \n",
    "- **간편한 사용법** \n",
    "  - 설치 및 사용법이 매우 간단하여 빠르게 프로토타입을 개발하고 검증할 수 있다. \n",
    "\n",
    "## 설치\n",
    "- <del>pip로 chromadb 설치시 **windows**에서는 c컴파일러 관련되어 에러가 난다. **conda 를 이용해 설치한다.**</del>\n",
    "- `conda install conda-forge::chromadb`\n",
    "- `pip install chromadb`\n",
    "- `pip install langchain-chroma`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ea95b-9244-4208-9d99-bb8698cc5d43",
   "metadata": {},
   "source": [
    "# Chroma API 를 이용해 연동\n",
    "- https://docs.trychroma.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70971742-500d-4470-89b0-b82f0b7cc30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8011c707-5a8e-4333-bb5f-c13bed9b30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "# 추가할 데이터\n",
    "document_list = [\n",
    "        \"This is a document about pineapple\",\n",
    "        \"This is a document about oranges\",\n",
    "        \"This is a document about sports\",\n",
    "        \"This is a document about langchain\",\n",
    "]\n",
    "ids = [str(uuid4()) for _ in range(len(document_list))]\n",
    "# 디비에 저장할 때 지정할 각 문서들의 ID 생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e693b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#  외부 Embedding 모델 \n",
    "from dotenv import load_dotenv\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "import os\n",
    "\n",
    "# 환경 변수 로드\n",
    "print(load_dotenv())\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# OpenAI 임베딩 함수 객체 생성\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=OPENAI_API_KEY,\n",
    "                model_name=\"text-embedding-3-small\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05dbf902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection - Database\n",
    "# Chroma DB와 연결\n",
    "import chromadb\n",
    "client = chromadb.Client()   # InMemory DB (데이터를 메모리에 저장)\n",
    "# client = chromadb.PersistentClient(path=\"vector_store/chroma/my_db\") # Local 파일에 저장.\n",
    "# client = chromadb.HttpClient(host=\"ip주소\", port=8000) # 서버로 서비스하는 chromadb에 연결\n",
    "\n",
    "# Collection(Database)을 생성\n",
    "collection_name = \"test_db\"\n",
    "collection = client.create_collection(\n",
    "    name=collection_name,\n",
    "    get_or_create=True, # collection이 있으면 연결, 없으면 생성. \n",
    "                        #  (False: 이미 있는 collection이면 Exception)\n",
    "    metadata={\"hnsw:space\":\"cosine\"}, # 코사인 유사도록 계산.\n",
    "    embedding_function=openai_ef\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4da147e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chromadb.api.models.Collection.Collection"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(collection) # collection 객체구나~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8b38daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### 데이터 추가\n",
    "collection.add(documents=document_list, ids=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "211eecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 유사도 검색\n",
    "result = collection.query(\n",
    "    query_texts=[\"deeplearning\", \"hawaii\"],  #질문\n",
    "    n_results=2,                 # 검색 결과 수\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0cc1a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['89bf8b74-9907-48ca-8bc8-3520d94b7008',\n",
       "   '5ff655d8-7c04-49b2-8f0d-3cc03d7aa265'],\n",
       "  ['5ff655d8-7c04-49b2-8f0d-3cc03d7aa265',\n",
       "   '89bf8b74-9907-48ca-8bc8-3520d94b7008']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['This is a document about langchain',\n",
       "   'This is a document about pineapple'],\n",
       "  ['This is a document about pineapple',\n",
       "   'This is a document about langchain']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None], [None, None]],\n",
       " 'distances': [[0.778143048286438, 0.814542293548584],\n",
       "  [0.7557111382484436, 0.8807901740074158]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7e66bf-e527-4bf2-a1c0-bfbb42fad70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb8d7bba-a840-477e-9ef3-666b1d5c1301",
   "metadata": {},
   "source": [
    "# Langchain을 이용해 Chroma 연동\n",
    "\n",
    "## Data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d281e998-76c4-46b7-8e96-ddd08e7ba42c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T12:09:44.559588Z",
     "iopub.status.busy": "2024-12-02T12:09:44.558586Z",
     "iopub.status.idle": "2024-12-02T12:09:46.061566Z",
     "shell.execute_reply": "2024-12-02T12:09:46.061566Z",
     "shell.execute_reply.started": "2024-12-02T12:09:44.559588Z"
    }
   },
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=1,\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=2,\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=3,\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=4,\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=5,\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=6,\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=7,\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=8,\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=9,\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=10,\n",
    ")\n",
    "document_list = [document_1, document_2, document_3, document_4, document_5, \n",
    "                 document_6, document_7, document_8, document_9, document_10,  ]\n",
    "ids = [str(uuid4()) for _ in range(len(document_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45667313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain-chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd05fc0a-c00e-4df8-a455-0333cbf17821",
   "metadata": {},
   "source": [
    "## Vector Store 생성, 연결\n",
    "- Chroma.from_documents()\n",
    "  - VectorStore를 초기화(생성)하고 문서를 추가한다.\n",
    "  - persist_directory를 지정하지 않으면 메모리에 저장된다.\n",
    "- Chroma()\n",
    "  - VectorStore와 연결."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aeed090-a67f-4599-a47d-0fe8b034603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "COLLECTION_NAME = \"example\"  # 컬렉션 이름 (RDB의 Database개념)\n",
    "PERSISTENT_PATH = 'vector_store/chroma/example_db' # 저장할 로컬 경로\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 1. 연결(생성)하면서 document들을 저장(upsert)\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=document_list,\n",
    "    ids=ids,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    persist_directory=PERSISTENT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0200a08d-7734-4b3e-874b-8d27b14f3369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 연결(생성)\n",
    "vector_store2 = Chroma(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    persist_directory=PERSISTENT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c700e-54ec-43a9-890b-ae804cf3ca3f",
   "metadata": {},
   "source": [
    "## VectorStore 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8ebf6ab-776b-4ae8-be97-7046de1873c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(name=example)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll = vector_store._collection # 연결된 collection 정보를 확인\n",
    "coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c586ed7-7d81-4a5f-ac49-f476ee980bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.count() # 저장된 데이터개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a46bf-3d08-4c00-97d1-f71488b39c76",
   "metadata": {},
   "source": [
    "## Add (추가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c040506-b68c-43ed-95d7-3184a10dc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_11 = Document(\n",
    "    page_content=\"랭체인은 대규모 언어 모델(LLM)을 효과적으로 활용하기 위한 도구와 프레임워크를 제공하는 오픈소스 라이브러리입니다.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=10,\n",
    ")\n",
    "\n",
    "document_12 = Document(\n",
    "    page_content=\"랭체인은 체인 구조를 사용하여 여러 LLM 작업을 연결하고, 이를 통해 더 복잡하고 맞춤화된 자연어 처리 애플리케이션을 개발할 수 있게 합니다\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=10,\n",
    ")\n",
    "\n",
    "document_13 = Document(\n",
    "    page_content=\"랭체인, AI 활용의 새 시대를 열다: 복잡한 언어 처리도 간단하게!\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92f9d5f9-aef7-4a5a-aec9-dbbd0ade4adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7247384c-6acb-49ba-b4c3-b15d8c8d8008',\n",
       " '9336b67e-9c68-4628-bd73-029af63da619',\n",
       " 'd6119088-b990-4498-813c-f6609cfab44f']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(\n",
    "    [document_11, document_12, document_13], \n",
    "    ids=[str(uuid4()), str(uuid4()), str(uuid4())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c87d42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f0d979-ea73-4dfb-abe5-ff328cc77b3e",
   "metadata": {},
   "source": [
    "## Update(갱신)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cf981b7-80e3-4a2f-b607-d73c409fdfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_document_13 = Document(\n",
    "    page_content=\"랭체인, AI 활용의 새 시대를 열다: 복잡한 언어 처리도 간단하게 처리할 수있는 Framework.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2960f4a5-6407-49cc-9272-7b8f37cc3dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.update_document(\n",
    "    document_id=\"0fc85d7f-1642-4c5b-9b67-0dbb9fbc2f0e\", # 바꿀 문서의 ID\n",
    "    document=new_document_13  # 바꿀 내용을 가진 Document객체\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "875ac893",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_document_12 = Document(\n",
    "    page_content=\"랭체인은 체인 구조를 사용하여 여러 LLM 작업을 연결할 수있다.\",\n",
    "    metadata={\"source\": \"website\"} # tweet -> website\n",
    ")\n",
    "\n",
    "update_document_13 = Document(\n",
    "    page_content=\"랭체인, AI 활용의 새 시대를 열다: 복잡한 언어 처리도 간단하게!\",\n",
    "    metadata={\"source\": \"news\"}\n",
    ")\n",
    "\n",
    "update_docs = [update_document_12, update_document_13]\n",
    "update_ids = ['8e66ec2a-5224-46c1-866e-4f7a027c174f','0fc85d7f-1642-4c5b-9b67-0dbb9fbc2f0e']\n",
    "\n",
    "vector_store.update_documents(documents=update_docs, ids=update_ids)\n",
    "# 한번에 여러개 update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47970aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['3d49bad2-abf4-41b5-b3eb-5cc278da4335',\n",
       "  '859b73e3-f095-4de8-b828-cc20d2051b76',\n",
       "  'e8288405-5c89-46d2-b78d-452203291d2b',\n",
       "  '97ce7d2f-224f-4e4b-90a1-cfcd85eca25f',\n",
       "  '7c9ba384-5281-4b03-9e27-1c46ae438351',\n",
       "  'c085eede-4d43-4a6e-b41b-345310eda427',\n",
       "  '431f17c1-1504-4be9-8af6-e0622990686c',\n",
       "  'c5e510d4-b7bc-40f7-bc0c-2657d238bef1',\n",
       "  '209677ba-ebbd-4a55-b41d-35b03b755866',\n",
       "  'f56bf32e-ae8a-49dc-a40e-fcb0eb794adf',\n",
       "  '818db729-f387-4c50-859b-d3dd1b88c9fb',\n",
       "  '8e66ec2a-5224-46c1-866e-4f7a027c174f',\n",
       "  '0fc85d7f-1642-4c5b-9b67-0dbb9fbc2f0e'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['I had chocolate chip pancakes and scrambled eggs for breakfast this morning.',\n",
       "  'The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.',\n",
       "  'Building an exciting new project with LangChain - come check it out!',\n",
       "  'Robbers broke into the city bank and stole $1 million in cash.',\n",
       "  \"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
       "  'Is the new iPhone worth the price? Read this review to find out.',\n",
       "  'The top 10 soccer players in the world right now.',\n",
       "  'LangGraph is the best framework for building stateful, agentic applications!',\n",
       "  'The stock market is down 500 points today due to fears of a recession.',\n",
       "  'I have a bad feeling I am going to get deleted :(',\n",
       "  '랭체인은 대규모 언어 모델(LLM)을 효과적으로 활용하기 위한 도구와 프레임워크를 제공하는 오픈소스 라이브러리입니다.',\n",
       "  '랭체인은 체인 구조를 사용하여 여러 LLM 작업을 연결할 수있다.',\n",
       "  '랭체인, AI 활용의 새 시대를 열다: 복잡한 언어 처리도 간단하게!'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': [{'source': 'tweet'},\n",
       "  {'source': 'news'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'news'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'website'},\n",
       "  {'source': 'website'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'news'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'website'},\n",
       "  {'source': 'news'}]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coll.get()  # 전체 저장된 문서를 조회\n",
    "vector_store.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28084f0a-4baf-4f94-8d06-6992d7551d81",
   "metadata": {},
   "source": [
    "## Delete(삭제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37216a6d-7192-438a-99f3-c1de8e2a0728",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_ids = ['209677ba-ebbd-4a55-b41d-35b03b755866','f56bf32e-ae8a-49dc-a40e-fcb0eb794adf']\n",
    "vector_store.delete(ids=del_ids)   # [삭제할 문서들의 id들]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c82b1400-e241-4e83-bdb6-c3fb0157306f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3350ace1-7997-4e5b-a6b1-52a5741a41ce",
   "metadata": {},
   "source": [
    "## Query(조회)\n",
    "- `similarity_search(query, k, filter)`\n",
    "  - 저장되 있는 item들 중 질의와 가장 유사한 것 k개를 찾는다. \n",
    "  - 찾은 결과를 filter 조건으로 필터링 한다. filter 조건은 meta-data의 정보를 이용한다.\n",
    "  - 질의어(query)는 text(자연어)로 입력한다.\n",
    "- `similarity_search_with_score(query, k, filter)`\n",
    "  - 저장되 있는 item들 중 질의와 가장 유사한 것 k개를 찾아 유사도 점수와 함께 반환\n",
    "- `similarity_search_by_vector(embedding, k, filter)`\n",
    "  - Embedding Vector 를 질의로 입력한다. (질의(query)를 문장이 아니라 embedding vector로 입력.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc28dff1-8241-4200-84ad-a3994595e9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='e8288405-5c89-46d2-b78d-452203291d2b', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
       " Document(id='818db729-f387-4c50-859b-d3dd1b88c9fb', metadata={'source': 'tweet'}, page_content='랭체인은 대규모 언어 모델(LLM)을 효과적으로 활용하기 위한 도구와 프레임워크를 제공하는 오픈소스 라이브러리입니다.'),\n",
       " Document(id='c5e510d4-b7bc-40f7-bc0c-2657d238bef1', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    query=\"Langchain이란 무엇인가요?\",\n",
    "    k=3, # 조회개수\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dce0f2-59e3-4c69-acac-82d606b9fe28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='3d49bad2-abf4-41b5-b3eb-5cc278da4335', metadata={'source': 'tweet'}, page_content='I had chocolate chip pancakes and scrambled eggs for breakfast this morning.'),\n",
       "  1.2473455667495728),\n",
       " (Document(id='c085eede-4d43-4a6e-b41b-345310eda427', metadata={'source': 'website'}, page_content='Is the new iPhone worth the price? Read this review to find out.'),\n",
       "  1.7842010259628296),\n",
       " (Document(id='818db729-f387-4c50-859b-d3dd1b88c9fb', metadata={'source': 'tweet'}, page_content='랭체인은 대규모 언어 모델(LLM)을 효과적으로 활용하기 위한 도구와 프레임워크를 제공하는 오픈소스 라이브러리입니다.'),\n",
       "  1.8591303825378418)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    query=\"아침에 무엇을 먹으면 좋을까?\",\n",
    "    k=3, # 조회개수\n",
    "    # filter={\"source\":\"tweet\"}  # metadata의 source키값이 tweet(source==tweet)\n",
    "    filter={\"source\":{\"$ne\":\"news\"}}   # source가 news가 아닌 것들.\n",
    "    #{metadata key: {\"연산자\":\"값\"}}\n",
    "    # {\"age\":{\"$gt\", 30}}  # age > 30\n",
    ")\n",
    "# 1. filter에 설정과 metadata를 비교해서 조회\n",
    "# 2. 1에서 조회된 문서들과 query간의 유사도를 체크\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cdf1d1-ea47-468d-8eef-d6681f7533f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7881354c",
   "metadata": {},
   "source": [
    "# 정리: Chroma 연동 과정 요약\n",
    "1. 데이터 준비   \n",
    "벡터로 변환할 텍스트 데이터와 그에 대응하는 문서 ID를 준비한다.\n",
    "\n",
    "2. 임베딩 모델 설정   \n",
    "텍스트를 수치 벡터로 변환할 임베딩 모델(OpenAI 등)을 설정한다.\n",
    "\n",
    "3. Chroma 벡터 데이터베이스 생성 및 연동      \n",
    "Chroma 인스턴스를 생성한 후, 문서 ID, 텍스트, 임베딩 벡터 등을 벡터 DB에 저장한다.\n",
    "\n",
    "이때 Chroma API를 직접 사용하거나 Langchain을 활용하여 연동하는 방법이 있다.\n",
    "\n",
    "- Chroma API 직접 사용:    \n",
    "가볍고 유연하게 원하는 로직을 구성할 수 있으며, 직접적인 제어가 가능하다.\n",
    "\n",
    "- Langchain을 이용한 연동:    \n",
    "문서 로딩, 임베딩, 검색, 응답까지의 파이프라인을 빠르게 구성할 수 있고, 다양한 기능과의 확장성이 뛰어나다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baa2586",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
