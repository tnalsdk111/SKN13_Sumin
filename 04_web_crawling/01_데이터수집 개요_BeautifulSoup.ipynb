{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ìˆ˜ì§‘ì— ë„ì›€ì´ ë˜ëŠ” ì‚¬ì´íŠ¸\n",
    "\n",
    "- **êµ­ê°€ í†µê³„í¬í„¸**\n",
    "    - https://kosis.kr\n",
    "    - í†µê³„ì²­ì—ì„œ ê´€ë¦¬í•˜ëŠ” ê³µê³µë°ì´í„° í¬í„¸ë¡œ ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ì˜ êµ­ê°€ í†µê³„ë°ì´í„°ë¥¼ ì œê³µí•œë‹¤.\n",
    "- **ê³µê³µë°ì´í„° í¬í„¸**\n",
    "    - https://www.data.go.kr\n",
    "    - í–‰ì • ì•ˆì „ë¶€ì—ì„œ ì œê³µí•˜ëŠ” ì •ë¶€ ë°ì´í„° í¬í„¸\n",
    "- **Kaggle**\n",
    "    - https://kaggle.com\n",
    "    - ë°ì´í„°ê³¼í•™ ê´€ë ¨ ê²½ì§„ëŒ€íšŒ í”Œë«í¼\n",
    "    - ë‹¤ì–‘í•œ ë°ì´í„°ë“¤ì„ ì œê³µí•œë‹¤.\n",
    "- **êµ¬ê¸€ ë°ì´í„°ì…‹ ì„œì¹˜**\n",
    "    - https://datasetsearch.research.google.com\n",
    "    - êµ¬ê¸€ì—ì„œ ì œê³µí•˜ëŠ” ë°ì´í„°ì…‹ ê²€ìƒ‰ ì‚¬ì´íŠ¸\n",
    "    - í‚¤ì›Œë“œë¥¼ ì´ìš©í•´ ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì„ ê²€ìƒ‰í•˜ê³  ë‹¤ìš´ë¡œë“œ ë°›ì„ ìˆ˜ ìˆë‹¤.\n",
    "- **AI Hub**\n",
    "    - https://aihub.or.kr\n",
    "    - êµ­ë‚´ì™¸ ê¸°ê´€/ê¸°ì—…ì—ì„œ ì¶”ì§„í•œ ì§€ëŠ¥ì •ë³´ì‚°ì—… ì¸í”„ë¼ ì¡°ì„±ì‚¬ì—…ì—ì„œ ê³µê°œí•œ AI í•™ìŠµìš© ë°ì´í„°ì…‹ë“¤ì„ ì œê³µí•œë‹¤.\n",
    "- **Roboflow Universe**\n",
    "    - https://universe.roboflow.com/\n",
    "    - Roboflow ë¼ëŠ” ì¸ê³µì§€ëŠ¥ íšŒì‚¬ì—ì„œ ìš´ì˜í•˜ëŠ” ë°ì´í„° ì €ì¥ì†Œ ì‚¬ì´íŠ¸ë¡œ ì»´í“¨í„°ë¹„ì „ ê´€ë ¨ ë°ì´í„°ì…‹ì„ ì£¼ë¡œ ì œê³µí•œë‹¤.\n",
    "- ê¸°íƒ€\n",
    "    - **ì§€ìì²´**: ì„œìš¸ì‹œ ì—´ë¦° ë°ì´í„°ê´‘ì¥, ê²½ê¸° ë°ì´í„° ë“œë¦¼\n",
    "    - **ê¸ˆìœµê´€ë ¨**: í•œêµ­ê±°ë˜ì†Œ, ê¸ˆìœµí†µê³„ì •ë³´ì‹œìŠ¤í…œë“±\n",
    "    - **ì˜í™”ê´€ë ¨**: ì˜í™”ì§„í¥ìœ„ì›íšŒ\n",
    "    - **ëŒ€ì¤‘êµí†µ**: êµ­ê°€êµí†µë°ì´í„°ë² ì´ìŠ¤, êµí†µì¹´ë“œ ë¹…ë°ì´í„° í†µí•©ì •ë³´ì‹œìŠ¤í…œë“±    \n",
    "    - **ê´€ê´‘ê´€ë ¨**: í•œêµ­ ê´€ê´‘ ë°ì´í„°ë©ë“±\n",
    "    - **ë‚ ì”¨ì •ë³´**: ê¸°ìƒì²­ ê¸°ìƒìë£Œ ê°œë°©í¬í„¸, ë„¤ì´ë²„ ë‚ ì”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [í¬ë¡¬ê°œë°œì ë„êµ¬](https://developers.google.com/web/tools/chrome-devtools/)\n",
    "\n",
    "- í¬ë¡¬ ê°œë°œì ë„êµ¬ëŠ” ì›¹ ê°œë°œ ë° ë””ë²„ê¹…ì„ ìœ„í•œ ê°•ë ¥í•œ ë„êµ¬ë¡œ í¬ë¡¬ ì›¹ë¸Œë¼ìš°ì €ì— ë‚´ì¥ë˜ì–´ ìˆë‹¤.\n",
    "    - `F12` ë‚˜ íŒì—… ë©”ë‰´ì—ì„œ `ê²€ì‚¬`ë¥¼ ì„ íƒí•œë‹¤.\n",
    "    - ì—£ì§€ ë¸Œë¼ìš°ì €ë„ ê°™ì€ ê°œë°œì ë„êµ¬ë¥¼ ì œê³µí•œë‹¤.\n",
    "- ì›¹ í˜ì´ì§€ì˜ HTML, CSS, JavaScript ì½”ë“œë¥¼ ê²€ì‚¬í•˜ê³  ìˆ˜ì •í•  ìˆ˜ ìˆìœ¼ë©°, ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì‘ë‹µ ë‚´ìš© ë¶„ì„, ì„±ëŠ¥ ë¶„ì„, ì½˜ì†” ë¡œê·¸ ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.\n",
    "- ì£¼ìš” ê¸°ëŠ¥\n",
    "    - **ìš”ì†Œ ê²€ì‚¬:** ì›¹ í˜ì´ì§€ì˜ íŠ¹ì • ìš”ì†Œë¥¼ ì„ íƒí•˜ì—¬ HTML êµ¬ì¡°, CSS ìŠ¤íƒ€ì¼, selector ë“±ì„ í™•ì¸í•œë‹¤.\n",
    "    - **ì½˜ì†”:** JavaScript ì½”ë“œë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆê³  Javascript ì‹¤í–‰ì‹œ ë°œìƒí•œ ì˜¤ë¥˜ ë©”ì‹œì§€ ë“±ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n",
    "    - **ì†ŒìŠ¤:** ì›¹ í˜ì´ì§€ì˜ JavaScript ì½”ë“œë¥¼ í™•ì¸í•  ìˆ˜ìˆê³  ë””ë²„ê¹…ì„ ìœ„í•œ ì¤‘ë‹¨ì (break point)ë¥¼ ì„¤ì •í•˜ê³  ë””ë²„ê¹…í•  ìˆ˜ ìˆë‹¤.\n",
    "    - **ë„¤íŠ¸ì›Œí¬:** ì›¹ í˜ì´ì§€ë¥¼ ìš”ì²­í•  ë•Œ ë°œìƒí•˜ëŠ” ìš”ì²­ ë° ì‘ë‹µ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì„±ëŠ¥ì„ ì¸¡ì •í•  ìˆ˜ ìˆë‹¤.\n",
    "    - **ì„±ëŠ¥:** ì›¹ í˜ì´ì§€ì˜ ë¡œë”© ì‹œê°„, ë Œë”ë§ ì„±ëŠ¥ì— ê±¸ë¦° ì‹œê°„ë“±ì„ ë¶„ì„í•  ìˆ˜ ìˆë‹¤.\n",
    "    - **ì• í”Œë¦¬ì¼€ì´ì…˜:** ì¿ í‚¤, ë¡œì»¬ ìŠ¤í† ë¦¬ì§€, ì„¸ì…˜ ìŠ¤í† ë¦¬ì§€ ë“± í´ë¼ì´ì–¸íŠ¸ ì €ì¥ ë°ì´í„° í™•ì¸ í•  ìˆ˜ ìˆë‹¤.\n",
    "- ê°œë°œì ë„êµ¬ëŠ” í¬ë¡¤ë§ ì‹œ í•„ìˆ˜ì ì¸ ë„êµ¬ì´ë©°, ìˆ˜ì§‘í•  í˜ì´ì§€ë¥¼ ë¶„ì„í•˜ëŠ”ë° ì‚¬ìš©ëœë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup\n",
    "- Markup ì–¸ì–´ parsing ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "    - HTMLì´ë‚˜ XML ë¬¸ì„œ ë‚´ì—ì„œ ì›í•˜ëŠ” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬.\n",
    "- https://www.crummy.com/software/BeautifulSoup/\n",
    "- https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "- ì„¤ì¹˜(ì•„ë‚˜ì½˜ë‹¤ í”„ë¡¬í”„íŠ¸ì—)\n",
    "    - beautifulsoup4 ì„¤ì¹˜\n",
    "        - pip install beautifulsoup4\n",
    "    - lxml ì„¤ì¹˜(html/xml parser)\n",
    "        - pip install lxml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì½”ë”© íŒ¨í„´\n",
    "1. ì¡°íšŒí•  HTMLë‚´ìš©ì„ ì „ë‹¬í•˜ì—¬ BeautifulSoup ê°ì²´ ìƒì„± \n",
    "1. BeautifulSoupê°ì²´ì˜ ë©”ì†Œë“œë“¤ì„ ì´ìš©í•´ ë¬¸ì„œë‚´ì—ì„œ í•„ìš”í•œ ì •ë³´ ì¡°íšŒ\n",
    "    - íƒœê·¸ì´ë¦„ê³¼ íƒœê·¸ ì†ì„±ìœ¼ë¡œ ì¡°íšŒ\n",
    "    - css selectorë¥¼ ì´ìš©í•´ ì¡°íšŒ\n",
    "    - . í‘œê¸°ë²•ì„ ì´ìš©í•œ íƒìƒ‰(Tree êµ¬ì¡° ìˆœì„œëŒ€ë¡œ íƒìƒ‰)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup ê°ì²´ ìƒì„±\n",
    "- BeautifulSoup(html str [, íŒŒì„œ])\n",
    "    - ë§¤ê°œë³€ìˆ˜\n",
    "        1. ì •ë³´ë¥¼ ì¡°íšŒí•  htmlì„ stringìœ¼ë¡œ ì „ë‹¬\n",
    "        2. íŒŒì„œ\n",
    "            - html.parser(ê¸°ë³¸íŒŒì„œ)\n",
    "            - lxml : ë§¤ìš° ë¹ ë¥´ë‹¤. html, xml íŒŒì‹± ê°€ëŠ¥(xml íŒŒì‹±ì€ lxmlë§Œ ê°€ëŠ¥)\n",
    "                - ì‚¬ìš©ì‹œ install í•„ìš” \n",
    "                - `conda install lxml`\n",
    "                - `pip install lxml`\n",
    "                - install í›„ ì»¤ë„ restart ì‹œí‚¨ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\SKN13SM\\SKN13_Sumin\\04_web_crawling\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example.html ìƒì„± ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "## example.html ìƒì„±\n",
    "# ë¬¸ì„œ ë‚´ìš©\n",
    "html_content = \"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>Example Page</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>Hello, BeautifulSoup!</h1>\n",
    "    <p>This is a paragraph.</p>\n",
    "    <a href=\"https://example.com\">Visit Example.com</a>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# íŒŒì¼ ìƒì„±\n",
    "with open(\"example.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "print(\"example.html ìƒì„± ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<html>\n",
      "  <head>\n",
      "    <title>Example Page</title>\n",
      " \n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "## íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "# HTMLì„ íŒŒì‹±í•˜ê¸° ìœ„í•œ BeautifulSoup ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤.\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# example.html íŒŒì¼ì„ ì½ê¸° ëª¨ë“œë¡œ ì—°ë‹¤.\n",
    "# r: read, ì½ê¸° ì „ìš© / t: text, í…ìŠ¤íŠ¸ ëª¨ë“œ \n",
    "with open(\"example.html\", \"rt\", encoding='utf-8') as fr:\n",
    "    html_doc = fr.read() # htmlì˜ ì „ì²´ ë‚´ìš©ì„ html_docì— ë¬¸ìì—´ë¡œ ì €ì¥í•œë‹¤.\n",
    "\n",
    "# ì˜ ë¶ˆëŸ¬ì™€ì¡ŒëŠ”ì§€ í™•ì¸ - ì²˜ìŒ 50ê¸€ìë§Œ ì¶œë ¥í•´ì„œ ë‚´ìš©ì„ í™•ì¸í•œë‹¤. \n",
    "print(html_doc[:50])\n",
    "print(type(html_doc)) # str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## html_docì„ beautifulsoupìœ¼ë¡œ íŒŒì‹±í•´ì„œ HTML êµ¬ì¡°ë¥¼ ë¶„ì„í•œë‹¤.\n",
    "soup = BeautifulSoup(html_doc, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Example Page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   Hello, BeautifulSoup!\n",
      "  </h1>\n",
      "  <p>\n",
      "   This is a paragraph.\n",
      "  </p>\n",
      "  <a href=\"https://example.com\">\n",
      "   Visit Example.com\n",
      "  </a>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## êµ¬ì¡°í™”ëœ HTMLì´ ì˜ˆì˜ê²Œ ì¶œë ¥ëœë‹¤. \n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¬¸ì„œë‚´ì—ì„œ ì›í•˜ëŠ” ì •ë³´ ê²€ìƒ‰\n",
    "\n",
    "### Tag ê°ì²´\n",
    "- í•˜ë‚˜ì˜ íƒœê·¸(element)ì— ëŒ€í•œ ì •ë³´ë¥¼ ë‹¤ë£¨ëŠ” ê°ì²´.\n",
    "    - BeautifulSoup ì¡°íšŒ ë©”ì†Œë“œë“¤ì˜ **ì¡°íšŒê²°ê³¼ì˜ ë°˜í™˜íƒ€ì….**\n",
    "    - ì¡°íšŒ í•¨ìˆ˜ë“¤ì´ ì°¾ì€ Elementê°€ í•˜ë‚˜ì¼ ê²½ìš° **Tag ê°ì²´ë¥¼, ì—¬ëŸ¬ê°œì¼ ê²½ìš° Tag ê°ì²´ë“¤ì„ ë‹´ì€ List(ResultSet)**ë¥¼ ë°˜í™˜í•œë‹¤.\n",
    "    - Tag ê°ì²´ëŠ” ì°¾ì€ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë©”ì†Œë“œì™€ Attributeë¥¼ ê°€ì§€ê³  ìˆë‹¤. ë˜ ì°¾ì€ Tagê°€ í•˜ìœ„ elementë¥¼ ê°€ì§ˆ ê²½ìš° ì°¾ì„ ìˆ˜ ìˆëŠ” ì¡°íšŒ ë©”ì†Œë“œë¥¼ ì œê³µí•œë‹¤.\n",
    "- ì£¼ìš” ì†ì„±/ë©”ì†Œë“œ\n",
    "    - **íƒœê·¸ì˜ ì†ì„±ê°’ ì¡°íšŒ**\n",
    "        - tagê°ì²´.get('ì†ì„±ëª…') \n",
    "        - tagê°ì²´\\['ì†ì„±ëª…'\\]\n",
    "        - ex) tag.get('href') ë˜ëŠ” tag\\['href'\\]\n",
    "    - **íƒœê·¸ë‚´ textê°’ ì¡°íšŒ**\n",
    "        - tagê°ì²´.get_text()\n",
    "        - tagê°ì²´.text\n",
    "        - ex) tag.get_text() ë˜ëŠ” tag.text\n",
    "    - **contents ì†ì„±**\n",
    "        - ì¡°íšŒí•œ íƒœê·¸ì˜ ëª¨ë“  ìì‹ ìš”ì†Œë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\n",
    "        - ex) child_list = tag.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì¡°íšŒ í•¨ìˆ˜\n",
    "- **íƒœê·¸ì˜ ì´ë¦„ìœ¼ë¡œ ì¡°íšŒ**\n",
    "    - find_all()\n",
    "    - find()\n",
    "- **css selectorë¥¼ ì´ìš©í•´ ì¡°íšŒ**\n",
    "    - select(), select_one()\n",
    "- **`.` í‘œê¸°ë²•(dot notation)**\n",
    "    - dom tree êµ¬ì¡°ì˜ ê³„ì¸µ ìˆœì„œëŒ€ë¡œ ì¡°íšŒ\n",
    "    - ìœ„ì˜ ë‘ë°©ì‹ìœ¼ë¡œ ì°¾ì€ tagë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê·¸ ì£¼ìœ„ì˜ element ë“¤ì„ ì°¾ì„ ë•Œ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### íƒœê·¸ì˜ ì´ë¦„ìœ¼ë¡œ ì¡°íšŒ\n",
    "- **find_all**(name=íƒœê·¸ëª…, attrs={ì†ì„±ëª…:ì†ì„±ê°’, ..})\n",
    "   - ì´ë¦„ì˜ ëª¨ë“  íƒœê·¸ elementë“¤ì„ ë¦¬ìŠ¤íŠ¸ì— ë‹´ì•„ ë°˜í™˜.\n",
    "   - ì—¬ëŸ¬ ì´ë¦„ì˜ íƒœê·¸ë¥¼ ì¡°íšŒí•  ê²½ìš° Listì— íƒœê·¸ëª…ë“¤ì„ ë¬¶ì–´ì„œ ì „ë‹¬í•œë‹¤.\n",
    "   - íƒœê·¸ì˜ attribute ì¡°ê±´ìœ¼ë¡œë§Œ ì¡°íšŒí•  ê²½ìš° nameì„ ìƒëµí•œë‹¤. \n",
    "- **find**(name=íƒœê·¸ëª…, attrs={ì†ì„±ëª…:ì†ì„±ê°’})\n",
    "    - ì´ë¦„ì˜ íƒœê·¸ì¤‘ ì²«ë²ˆì§¸ íƒœê·¸ elementë¥¼ ë°˜í™˜."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¥° ì˜ˆìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example_news.html íŒŒì¼ ìƒì„±\n",
    "\n",
    "# ë¬¸ì„œ ë‚´ìš©\n",
    "html_content = \"\"\"\n",
    "<html>\n",
    "  <body>\n",
    "    <div class=\"news\">\n",
    "      <h2>ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤</h2>\n",
    "      <p class=\"content\">ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤.</p>\n",
    "    </div>\n",
    "    <div class=\"news\">\n",
    "      <h2>ìŠ¤í¬ì¸  ë‰´ìŠ¤</h2>\n",
    "      <p class=\"content\">ì¶•êµ¬ì—ì„œ ìŠ¹ë¦¬í–ˆìŠµë‹ˆë‹¤.</p>\n",
    "    </div>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# íŒŒì¼ ìƒì„±\n",
    "# open() í•¨ìˆ˜ë¡œ íŒŒì¼ ì—´ê¸°\n",
    "# ì£¼ìš” íŒŒë¼ë¯¸í„°: íŒŒì¼ëª…, ëª¨ë“œ, ì¸ì½”ë”©\n",
    "with open(\"example_news.html\", \"w\", encoding = \"utf-8\") as f: \n",
    "    f.write(html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<html>\n",
      "  <body>\n",
      "    <div class=\"news\">\n",
      "      <h2>ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤</h2>\n",
      "      <p class=\"content\">ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤.</p>\n"
     ]
    }
   ],
   "source": [
    "## íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "# HTMLì„ íŒŒì‹±í•˜ê¸° ìœ„í•œ BeautifulSoup ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤. \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# example_news.htmlì„ ì½ê¸° ëª¨ë“œë¡œ ì—°ë‹¤.\n",
    "with open(\"example_news.html\", \"rt\", encoding = \"utf-8\") as fr:\n",
    "    html_doc = fr.read()\n",
    "\n",
    "# ì˜ ë¶ˆëŸ¬ì™€ì¡ŒëŠ”ì§€ í™•ì¸\n",
    "print(html_doc[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¥° íŒŒì‹±ì´ë€? (Parsing)\n",
    "- **íŒŒì‹± = \"ë¬¸ì¥ì„ ë¶„ì„í•´ì„œ êµ¬ì¡°ë¥¼ ì´í•´í•˜ëŠ” ì¼\"ì´ì•¼!**\n",
    "\n",
    "- ì‚¬ëŒì´ ê¸€ì„ ì½ìœ¼ë©´ ë¬¸ì¥ì˜ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ì–ì•„?\n",
    "â†’ ì£¼ì–´, ë™ì‚¬, ëª©ì ì–´ì²˜ëŸ¼.\n",
    "\n",
    "- ì»´í“¨í„°ë„ HTML ê°™ì€ ë¬¸ì„œë¥¼ ê·¸ëƒ¥ ì½ì„ ìˆ˜ëŠ” ì—†ê³ ,\n",
    "ë¶„ì„í•´ì„œ **íƒœê·¸ì˜ êµ¬ì¡°ë¥¼ ì´í•´**í•´ì•¼ ë‹¤ë£° ìˆ˜ ìˆì–´!\n",
    "\n",
    "- ê·¸ê²Œ ë°”ë¡œ íŒŒì‹±ì´ì•¼. ğŸ’¡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`soup = BeautifulSoup(html_doc, \"lxml\")` ì´ ì½”ë“œëŠ” **HTML ë¬¸ì„œë¥¼ íŒŒì‹±**í•´ì„œ **BeautifulSoup ê°ì²´ë¡œ ë§Œë“œëŠ” ì½”ë“œ**ì•¼."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html_docì„ BeautifulSoupìœ¼ë¡œ íŒŒì‹±\n",
    "soup = BeautifulSoup(html_doc, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **html_doc**: ë¬¸ìì—´ë¡œ ë˜ì–´ìˆëŠ” **html ë¬¸ì„œ**\n",
    "- **\"lxml\"**: ì–´ë–¤ **íŒŒì„œ(parser)**ë¥¼ ì“¸ ê±´ì§€ ì§€ì •. lxml íŒŒì„œëŠ” ë¹ ë¥´ê³  ì‹ ë¢°ì„±ì´ ì¢‹ë‹¤. \n",
    "- **soup**: íƒœê·¸ êµ¬ì¡°ê°€ ë¶„ì„ëœ html ë¬¸ì„œë¥¼ ë‹´ê³  ìˆëŠ” **BeautifulSoup ê°ì²´**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<html>\n",
      "  <body>\n",
      "    <div class=\"news\">\n",
      "      <h2>ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤</h2>\n",
      "      <p class=\"content\">ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤.</p>\n",
      "    </div>\n",
      "    <div class=\"news\">\n",
      "      <h2>ìŠ¤í¬ì¸  ë‰´ìŠ¤</h2>\n",
      "      <p class=\"content\">ì¶•êµ¬ì—ì„œ ìŠ¹ë¦¬í–ˆìŠµë‹ˆë‹¤.</p>\n",
      "    </div>\n",
      "  </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(html_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<body>\n",
      "<div class=\"news\">\n",
      "<h2>ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤</h2>\n",
      "<p class=\"content\">ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤.</p>\n",
      "</div>\n",
      "<div class=\"news\">\n",
      "<h2>ìŠ¤í¬ì¸  ë‰´ìŠ¤</h2>\n",
      "<p class=\"content\">ì¶•êµ¬ì—ì„œ ìŠ¹ë¦¬í–ˆìŠµë‹ˆë‹¤.</p>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup) # íŒŒì‹± ê²°ê³¼ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <div class=\"news\">\n",
      "   <h2>\n",
      "    ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤\n",
      "   </h2>\n",
      "   <p class=\"content\">\n",
      "    ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤.\n",
      "   </p>\n",
      "  </div>\n",
      "  <div class=\"news\">\n",
      "   <h2>\n",
      "    ìŠ¤í¬ì¸  ë‰´ìŠ¤\n",
      "   </h2>\n",
      "   <p class=\"content\">\n",
      "    ì¶•êµ¬ì—ì„œ ìŠ¹ë¦¬í–ˆìŠµë‹ˆë‹¤.\n",
      "   </p>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¥° íƒœê·¸ ì¡°íšŒì˜ ì¶”ì²œ í•™ìŠµ íë¦„\n",
    "- 1ë‹¨ê³„) íƒœê·¸ëª…/í´ë˜ìŠ¤ë¡œ ìš”ì†Œ ì°¾ê¸°: `find()`, `find_all()`\n",
    "\n",
    "- 2ë‹¨ê³„) í…ìŠ¤íŠ¸ êº¼ë‚´ê¸°: `get_text()`\n",
    "\n",
    "- 3ë‹¨ê³„) ì†ì„± êº¼ë‚´ê¸°:`[\"href\"]`, `get(\"src\")`\n",
    "\n",
    "- 4ë‹¨ê³„) CSS ì„ íƒìë¡œ ì •ë°€í•˜ê²Œ ì°¾ê¸°:`select()`, `select_one()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1ë‹¨ê³„: íƒœê·¸ëª…, í´ë˜ìŠ¤ë¡œ ìš”ì†Œ ì°¾ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ëª¨ë“  ë‰´ìŠ¤ êµ¬ì—­ ê°€ì ¸ì˜¤ê¸°: class = \"news\"ì¸ ê²ƒ\n",
      "\n",
      "[<div class=\"news\">\n",
      "<h2>ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤</h2>\n",
      "<p class=\"content\">ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤.</p>\n",
      "</div>, <div class=\"news\">\n",
      "<h2>ìŠ¤í¬ì¸  ë‰´ìŠ¤</h2>\n",
      "<p class=\"content\">ì¶•êµ¬ì—ì„œ ìŠ¹ë¦¬í–ˆìŠµë‹ˆë‹¤.</p>\n",
      "</div>] \n",
      "\n",
      "\n",
      "2. ê° ë‰´ìŠ¤ì˜ ë³¸ë¬¸ë§Œ ê°€ì ¸ì˜¤ê¸° - div(êµ¬ì—­ ë‚˜ëˆ„ëŠ” íƒœê·¸) ì•„ë˜ p(ë³¸ë¬¸ íƒœê·¸):\n",
      "\n",
      "[<p class=\"content\">ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤.</p>, <p class=\"content\">ì¶•êµ¬ì—ì„œ ìŠ¹ë¦¬í–ˆìŠµë‹ˆë‹¤.</p>]\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë“  ë‰´ìŠ¤ êµ¬ì—­ ê°€ì ¸ì˜¤ê¸°\n",
    "print(\"1. ëª¨ë“  ë‰´ìŠ¤ êµ¬ì—­ ê°€ì ¸ì˜¤ê¸°: class = \\\"news\\\"ì¸ ê²ƒ\\n\")\n",
    "print(soup.find_all(\"div\", class_=\"news\"), \"\\n\\n\") \n",
    "\n",
    "# ê° ë‰´ìŠ¤ì˜ ë³¸ë¬¸ë§Œ\n",
    "print(\"2. ê° ë‰´ìŠ¤ì˜ ë³¸ë¬¸ë§Œ ê°€ì ¸ì˜¤ê¸° - div(êµ¬ì—­ ë‚˜ëˆ„ëŠ” íƒœê·¸) ì•„ë˜ p(ë³¸ë¬¸ íƒœê·¸):\\n\")\n",
    "print(soup.select(\"div.news > p.content\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2ë‹¨ê³„: í…ìŠ¤íŠ¸ êº¼ë‚´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‰´ìŠ¤ ì œëª© ê°€ì ¸ì˜¤ê¸°:\n",
      "ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤\n"
     ]
    }
   ],
   "source": [
    "print(\"ë‰´ìŠ¤ ì œëª© ê°€ì ¸ì˜¤ê¸°:\")\n",
    "print(soup.find(\"h2\").get_text())\n",
    "# 1. find(\"h1\"): \"h2\" íƒœê·¸ë¥¼ ê°€ì§„ ìš”ì†Œë¥¼ ì°¾ì•„ì„œ\n",
    "# 2. get_text(): íƒìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¨ë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ©· (ì°¸ê³ ) AttributeError: ë³¸ë¬¸ì— \"h1\" íƒœê·¸ê°€ ì—†ëŠ”ë° find(\"h1\") í•œ ê²½ìš°\n",
    "- AttributeError: 'NoneType' object has no attribute 'get_text'\n",
    "- ì´ ë§ì€ ì‰½ê²Œ ë§í•´ì„œ:\n",
    "  - soup.find(\"h1\")ê°€ ì•„ë¬´ê²ƒë„ ëª» ì°¾ì•˜ì–´ â†’ ê·¸ë˜ì„œ Noneì´ ë‚˜ì™”ê³ \n",
    "  - ê·¸ Noneí•œí…Œ .get_text() í•˜ë‹ˆê¹Œ ì—ëŸ¬ ë‚œ ê±°ì•¼! âŒ\n",
    "\n",
    "- â˜‘ï¸ í•´ê²°ë°©ë²• 1: HTMLì— \"h1\" íƒœê·¸ê°€ ìˆëŠ”ì§€ í™•ì¸í•œë‹¤. \n",
    "- â˜‘ï¸ í•´ê²°ë°©ë²• 2: ifë¬¸ìœ¼ë¡œ None ì—¬ë¶€ ì²´í¬ (ë°”ë¡œ ì•„ë˜ ì½”ë“œ)\n",
    "- â˜‘ï¸ í•´ê²°ë°©ë²• 3: `print(soup.prettify())` ì½”ë“œë¡œ êµ¬ì¡° í™•ì¸í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 íƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ ğŸ˜¥\n"
     ]
    }
   ],
   "source": [
    "title_tag = soup.find(\"h1\")\n",
    "\n",
    "if title_tag:\n",
    "    print(\"ë‰´ìŠ¤ ì œëª©:\", title_tag.get_text())\n",
    "else:\n",
    "    print(\"h1 íƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ ğŸ˜¥\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <div class=\"news\">\n",
      "   <h2>\n",
      "    ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤\n",
      "   </h2>\n",
      "   <p class=\"content\">\n",
      "    ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤.\n",
      "   </p>\n",
      "   <a href=\"https://search.naver.com/search.naver?where=nexearch&amp;sm=top_hty&amp;fbm=0&amp;ie=utf8&amp;query=%EB%82%A0%EC%94%A8\">\n",
      "    ì˜¤ëŠ˜ ë‚ ì”¨ ë³´ê¸°\n",
      "   </a>\n",
      "  </div>\n",
      "  <div class=\"news\">\n",
      "   <h2>\n",
      "    ìŠ¤í¬ì¸  ë‰´ìŠ¤\n",
      "   </h2>\n",
      "   <p class=\"content\">\n",
      "    ì¶•êµ¬ì—ì„œ ìŠ¹ë¦¬í–ˆìŠµë‹ˆë‹¤.\n",
      "   </p>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### ì ì‹œ ìˆ˜ì •!\n",
    "\n",
    "# <p> íƒœê·¸ ì„ íƒ\n",
    "p_tag = soup.find(\"p\", class_=\"content\")\n",
    "# (ì°¸ê³ ) ì²« ë²ˆì§¸ p íƒœê·¸ ë’¤ì— ë‚´ìš©ì„ ë¶™ì¼ ê±°ë¼ find()ë¥¼ ì”€. \n",
    "# ë‘ ë²ˆì§¸ ê²ƒì„ ìˆ˜ì •í•˜ê³  ì‹¶ë‹¤ë©´ find_all() ì¨ì„œ ë‹¤ ë¶ˆëŸ¬ì˜¤ì.\n",
    "\n",
    "# <a> íƒœê·¸ ìƒˆë¡œ ë§Œë“¤ê¸°\n",
    "new_a = soup.new_tag(\"a\", href=\"https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query=%EB%82%A0%EC%94%A8\")\n",
    "new_a.string = \"ì˜¤ëŠ˜ ë‚ ì”¨ ë³´ê¸°\"\n",
    "\n",
    "# <p> íƒœê·¸ ë°”ë¡œ **ë’¤ì—** <a> íƒœê·¸ ì¶”ê°€\n",
    "p_tag.insert_after(new_a)\n",
    "\n",
    "# ê²°ê³¼ ë³´ê¸°\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤ì œ html íŒŒì¼ì— ì €ì¥í•˜ë ¤ë©´ open() í•¨ìˆ˜ë¥¼ í†µí•´ write() í•´ì£¼ì–´ì•¼ í•œë‹¤.\n",
    "with open(\"example_news.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(str(soup))  # ìˆ˜ì •ëœ soup ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•´ì„œ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3ë‹¨ê³„: ì†ì„± êº¼ë‚´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find(\"h2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"example.html\", \"rt\", encoding=\"utf-8\") as fr:\n",
    "    html_doc = fr.read()\n",
    "\n",
    "soup = BeautifulSoup(html_doc, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = soup.find_all(\"div\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<div class=\"news\">\n",
       " <h2>ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤</h2>\n",
       " <p class=\"content\">ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤.</p><a href=\"https://search.naver.com/search.naver?where=nexearch&amp;sm=top_hty&amp;fbm=0&amp;ie=utf8&amp;query=%EB%82%A0%EC%94%A8\">ì˜¤ëŠ˜ ë‚ ì”¨ ë³´ê¸°</a>\n",
       " </div>,\n",
       " <div class=\"news\">\n",
       " <h2>ìŠ¤í¬ì¸  ë‰´ìŠ¤</h2>\n",
       " <p class=\"content\">ì¶•êµ¬ì—ì„œ ìŠ¹ë¦¬í–ˆìŠµë‹ˆë‹¤.</p>\n",
       " </div>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: \n",
      "ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤\n",
      "ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤.ì˜¤ëŠ˜ ë‚ ì”¨ ë³´ê¸°\n",
      " \n",
      "ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤\n",
      "ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤.ì˜¤ëŠ˜ ë‚ ì”¨ ë³´ê¸°\n",
      "\n",
      "classì†ì„±ê°’: ['news'] ['news']\n"
     ]
    }
   ],
   "source": [
    "tag1 = result[0]\n",
    "print(\"content:\", tag1.text, tag1.get_text())\n",
    "print(\"classì†ì„±ê°’:\", tag1.get(\"class\"), tag1['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n",
      "--------------------------------------------------\n",
      "<div class=\"news\">\n",
      "<h2>ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤</h2>\n",
      "<p class=\"content\">ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤.</p><a href=\"https://search.naver.com/search.naver?where=nexearch&amp;sm=top_hty&amp;fbm=0&amp;ie=utf8&amp;query=%EB%82%A0%EC%94%A8\">ì˜¤ëŠ˜ ë‚ ì”¨ ë³´ê¸°</a>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "result = soup.find(\"div\")\n",
    "print(type(result))\n",
    "print(\"-\"*50)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content text: \n",
      "ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤\n",
      "ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤.ì˜¤ëŠ˜ ë‚ ì”¨ ë³´ê¸°\n",
      "\n",
      "--------------------------------------------------\n",
      "content text: \n",
      "ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤\n",
      "ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤.ì˜¤ëŠ˜ ë‚ ì”¨ ë³´ê¸°\n",
      "\n",
      "--------------------------------------------------\n",
      "attribueì˜ value: ['news']\n",
      "--------------------------------------------------\n",
      "attribueì˜ value: ['news']\n"
     ]
    }
   ],
   "source": [
    "# íƒœê·¸ì˜ contentì™€ attribute ì¡°íšŒ\n",
    "\n",
    "print(\"content text:\", result.text)\n",
    "print(\"-\"*50)\n",
    "print(\"content text:\", result.get_text())\n",
    "print(\"-\"*50)\n",
    "print(\"attribueì˜ value:\", result.get(\"class\"))\n",
    "print(\"-\"*50)\n",
    "print(\"attribueì˜ value:\", result[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " <h2>ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤</h2>,\n",
       " '\\n',\n",
       " <p class=\"content\">ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤.</p>,\n",
       " <a href=\"https://search.naver.com/search.naver?where=nexearch&amp;sm=top_hty&amp;fbm=0&amp;ie=utf8&amp;query=%EB%82%A0%EC%94%A8\">ì˜¤ëŠ˜ ë‚ ì”¨ ë³´ê¸°</a>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# íƒœê·¸ì˜ ëª¨ë“  ìì‹ ìš”ì†Œë“¤ ì¡°íšŒ\n",
    "result.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"https://search.naver.com/search.naver?where=nexearch&amp;sm=top_hty&amp;fbm=0&amp;ie=utf8&amp;query=%EB%82%A0%EC%94%A8\">ì˜¤ëŠ˜ ë‚ ì”¨ ë³´ê¸°</a>]\n",
      "--------------------------------------------------\n",
      "[<a href=\"https://search.naver.com/search.naver?where=nexearch&amp;sm=top_hty&amp;fbm=0&amp;ie=utf8&amp;query=%EB%82%A0%EC%94%A8\">ì˜¤ëŠ˜ ë‚ ì”¨ ë³´ê¸°</a>]\n",
      "--------------------------------------------------\n",
      "[]\n",
      "--------------------------------------------------\n",
      "[]\n",
      "--------------------------------------------------\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "result = soup.find_all(\"a\") \n",
    "print(result)\n",
    "print(\"-\"*50)\n",
    "result = soup.find_all([\"a\", \"span\"])  #í•œë²ˆì— ì—¬ëŸ¬ì´ë¦„ì˜ íƒœê·¸ë“œì„ ì¡°íšŒ.\n",
    "print(result)\n",
    "print(\"-\"*50)\n",
    "result = soup.find_all(\"div\", attrs={\"class\":\"name\"}) # íƒœê·¸ì´ë¦„ + ì†ì„±\n",
    "print(result)\n",
    "print(\"-\"*50)\n",
    "result = soup.find_all(\"div\", attrs={\"class\":\"animal_info\", \"id\":\"animal1\"}) # ì†ì„± ì¡°ê±´ì´ ì—¬ëŸ¬ê°œ\n",
    "print(result)\n",
    "print(\"-\"*50)\n",
    "result = soup.find_all(\"a\", attrs={\"href\":\"https://www.coexaqua.com\"})\n",
    "\n",
    "# import re\n",
    "# result = soup.find_all(\"a\", attrs={\"href\":re.compile(r\".com$\")}) # ì •ê·œí‘œí˜„ì‹-.comìœ¼ë¡œ ëë‚˜ëŠ”.\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for tag in result:\n",
    "    print(tag.text, tag['href'])\n",
    "    result_list.append([tag.text, tag['href']]) # list[text, href]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSS Selectorë¥¼ ì´ìš©í•´ ì¡°íšŒ\n",
    "- **select(selector='cssì…€ë ‰í„°')**\n",
    "    - css ì…€ë ‰í„°ì™€ ì¼ì¹˜í•˜ëŠ” tagë“¤ì„ ë°˜í™˜í•œë‹¤.\n",
    "- **select_one(selector='cssì…€ë ‰í„°')**\n",
    "    - css ì…€ë ‰í„°ì™€ ì¼ì¹˜í•˜ëŠ” tagë¥¼ ë°˜í™˜í•œë‹¤.\n",
    "    - ì¼ì¹˜í•˜ëŠ” ê²ƒì´ ì—¬ëŸ¬ê°œì¼ ê²½ìš° ì²«ë²ˆì§¸ ê²ƒ í•˜ë‚˜ë§Œ ë°˜í™˜í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"example.html\", \"rt\", encoding=\"utf-8\") as fr:\n",
    "    html_doc = fr.read()\n",
    "\n",
    "soup = BeautifulSoup(html_doc, \"lxml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"https://search.naver.com/search.naver?where=nexearch&amp;sm=top_hty&amp;fbm=0&amp;ie=utf8&amp;query=%EB%82%A0%EC%94%A8\">ì˜¤ëŠ˜ ë‚ ì”¨ ë³´ê¸°</a>]\n"
     ]
    }
   ],
   "source": [
    "# css selectorë¥¼ ì´ìš©í•œ ì¡°íšŒ\n",
    "\n",
    "result = soup.select(\"a\")         #  íƒœê·¸ì´ë¦„(a)  \n",
    "# result = soup.select(\"a, span\") # íƒœê·¸ì´ë¦„(ì—¬ëŸ¬ê°œ)\n",
    "# result = soup.select(\"ul a\")    # ulì˜ ìì†ì¸ aíƒœê·¸ ì°¾ëŠ”ë‹¤.\n",
    "\n",
    "# result = soup.select_one(\"#animal1\")             # ëª¨ë“  íƒœê·¸ì¤‘ id=animal1\n",
    "# result = soup.select(\"ul + div\")                 # ulì˜ ë‹¤ìŒ í˜•ì œ íƒœê·¸ì¤‘ div\n",
    "# result = soup.select(\"body > div:nth-child(3)\")  # bodyì˜ 3ë²ˆì§¸ ìì‹ div\n",
    "\n",
    "# result = soup.select(\"a[href]\")                        # href ì†ì„±ì´ ìˆëŠ” a íƒœê·¸ë“¤\n",
    "# result = soup.select(\"a[href='http://www.naver.com']\") # href='http://www.naver.com' ì†ì„±ì„ ê°€ì§„ a íƒœê·¸\n",
    "# result = soup.select('a[href$=\".do\"]')                 # $=  href ì†ì„±ê°’ì´ .doë¡œ ëë‚˜ëŠ” aíƒœê·¸ë“¤\n",
    "# result = soup.select('a[href^=\"https\"]')               # =^  href ì†ì„±ê°’ì´ httpsë¡œ ì‹œì‘í•˜ëŠ” aíƒœê·¸\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in result:\n",
    "    print(tag.text, tag['href'], tag.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
