{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef06541a-3111-46cb-a3be-4b50d8267e1a",
   "metadata": {},
   "source": [
    "# Transformers 를 이용해 Backbone 사용\n",
    "\n",
    "## Transformers 설치\n",
    "- `pip install transformers`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d4825a-fe9f-4d1e-b9e0-7bb78745b840",
   "metadata": {},
   "source": [
    "### Tokenizer, Model Loading\n",
    "- Huggingface 모델 허브에서 제공하는 처리 모델을 다운받아 로딩한다.\n",
    "- 다운로드된 모델은 `사용자 home 디렉토리\\.cache\\huggingface` 에 저장된다.\n",
    "- 미리 학습된 언어 모델을 다운받아 사용할 때는 그 언어모델이 사용한 tokenizer를 같이 받아서 사용한다.\n",
    "\n",
    "### [Auto Classes](https://huggingface.co/docs/transformers/model_doc/auto)\n",
    "- Huggingface 에서 제공하는 다양한 모델들은 손쉽게 불러오고 사용할 수 있도록 설계된 유틸리티 클래스들을 말한다.\n",
    "- 미리 학습된 특정 모델의 이름(모델 허브상에서 제공되는 이름)이나 저장된 local 경로를 제공하면 해당 모델에 맞는 적절한 클래스와 구성 요소를 자동으로 로드한다.\n",
    "- 사용자는 모델을 사용하기 위한 정확한 클래스를 몰라도 쉽게 다양한 종류의 모델을 사용할 수있다.\n",
    "\n",
    "#### 주요 Auto Class\n",
    "- 기본 모델 Loading\n",
    "    1. **AutoModel**\n",
    "       - 주어진 모델 이름에 맞는 사전 학습된 모델을 자동으로 로드한다.\n",
    "       - 예: `AutoModel.from_pretrained(\"bert-base-uncased\")`: BERT 모델을 로드한다.\n",
    "    2. **AutoTokenizer**\n",
    "       - 해당 모델에 적합한 토크나이저를 자동으로 로드한다.\n",
    "       - 예: `AutoTokenizer.from_pretrained(\"bert-base-uncased\")`: BERT 모델에 맞는 토크나이저를 로드한다.\n",
    "    3. **AutoConfig**\n",
    "       - 모델의 설정(config)을 자동으로 로드한다. 모델 설정에는 모델의 하이퍼파라미터와 모델 구조 정보가 포함된다. 이 설정을 이용해 모델을 생성할 수있다.\n",
    "       - 예: `AutoConfig.from_pretrained(\"bert-base-uncased\")`\n",
    "- Task 처리 모델 Loading\n",
    "    - Pretrained backbone 모델에 각 task 에 맞는 estimator layer를 추가한 모델을 생성해 제공한다.\n",
    "    - 주요 모델들\n",
    "        1. **AutoModelForSequenceClassification**\n",
    "           - 시퀀스(Text) 분류 작업을 위한 모델을 자동으로 로드한다.\n",
    "           - 예: `AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")`\n",
    "        2. **AutoModelForQuestionAnswering**\n",
    "           - 질문-응답 작업을 위한 모델을 자동으로 로드한다.\n",
    "           - 예: `AutoModelForQuestionAnswering.from_pretrained(\"bert-base-uncased\")`\n",
    "        3. **AutoModelForTokenClassification**\n",
    "           - 토큰 분류 작업(예: 개체명 인식)을 위한 모델을 자동으로 로드한다.\n",
    "           - 예: `AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b9ab90-27b3-4e3a-b907-8c6345552ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\dl\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef773cb-9947-4b0b-9deb-16bb7ea1b61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.modeling_bert.BertModel'>\n",
      "<class 'transformers.models.bert.configuration_bert.BertConfig'>\n"
     ]
    }
   ],
   "source": [
    "model_id=\"bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "print(type(tokenizer))\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "print(type(model))\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "print(type(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72627367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1045, 2572, 1037, 2879, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_txt = \"I am a boy.\"\n",
    "token = tokenizer(\n",
    "    raw_txt,\n",
    "    return_tensors=\"pt\")\n",
    "# 토큰화 결과: default-list, \"pt\"-torch.tensor, \"tf\"-tensorflow.tnesor, \"np\"-np.array\n",
    "token\n",
    "# input_ids: 토큰 id\n",
    "# attention_mask: input_ids의 각 토큰들이 실제 토큰인지 [PAD] 토큰인지 여부\n",
    "# 1: 유효(실제) 문자열 토큰, 0: [PAD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22c3ab1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "027af85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "context_vector = model(**token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d877fa4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.1779,  0.1550, -0.1707,  ...,  0.0410,  0.4759,  0.5032],\n",
       "         [-0.1397,  0.2318, -0.2807,  ...,  0.0090,  0.5446,  0.2929],\n",
       "         [-0.2585,  0.2294,  0.1758,  ..., -0.1466,  0.3572,  0.2033],\n",
       "         ...,\n",
       "         [-0.0560,  0.1688,  0.5574,  ..., -0.2375,  0.8589, -1.2152],\n",
       "         [-0.1773, -0.7334, -0.3479,  ...,  0.4004,  0.6529, -0.3144],\n",
       "         [ 0.7643,  0.1765, -0.0638,  ..., -0.0126, -0.4987, -0.3970]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-8.9368e-01, -4.8297e-01, -7.3119e-01,  8.0403e-01,  4.5552e-01,\n",
       "         -1.2779e-01,  8.5415e-01,  1.8577e-01, -7.4326e-01, -9.9997e-01,\n",
       "         -3.2631e-01,  9.5897e-01,  9.8007e-01,  5.2694e-01,  9.2719e-01,\n",
       "         -7.5958e-01, -5.3485e-01, -6.0855e-01,  3.3701e-01, -6.5122e-01,\n",
       "          7.5661e-01,  9.9989e-01, -6.7539e-02,  3.4064e-01,  4.4406e-01,\n",
       "          9.8609e-01, -7.1002e-01,  8.9186e-01,  9.6556e-01,  7.6039e-01,\n",
       "         -6.8049e-01,  1.1768e-01, -9.9085e-01, -3.8280e-02, -7.7160e-01,\n",
       "         -9.9192e-01,  4.2181e-01, -7.0604e-01,  1.4266e-01,  9.4905e-02,\n",
       "         -8.9546e-01,  2.8781e-01,  9.9994e-01, -1.1917e-01,  3.3448e-01,\n",
       "         -2.5981e-01, -1.0000e+00,  2.8258e-01, -8.8364e-01,  8.9288e-01,\n",
       "          7.9535e-01,  8.0212e-01,  2.3823e-01,  4.1031e-01,  5.5462e-01,\n",
       "         -1.2720e-01, -1.0329e-01,  9.2250e-02, -2.7279e-01, -5.8499e-01,\n",
       "         -6.9564e-01,  4.5408e-01, -8.1031e-01, -8.4527e-01,  8.7022e-01,\n",
       "          7.3006e-01, -1.6827e-01, -1.9859e-01,  2.9282e-02, -7.4254e-02,\n",
       "          8.6979e-01,  1.7370e-01, -6.4095e-02, -8.0121e-01,  4.3773e-01,\n",
       "          2.2301e-01, -6.9543e-01,  1.0000e+00, -6.2082e-01, -9.7454e-01,\n",
       "          6.2846e-01,  6.4645e-01,  6.2350e-01, -1.4717e-01,  2.5241e-01,\n",
       "         -1.0000e+00,  5.0894e-01, -5.3119e-03, -9.9102e-01,  2.3817e-01,\n",
       "          4.5873e-01, -2.6714e-01,  3.9709e-01,  6.8833e-01, -3.9454e-01,\n",
       "         -5.2951e-01, -3.7954e-01, -7.5745e-01, -2.1138e-01, -3.3056e-01,\n",
       "          4.8783e-02, -1.9719e-01, -2.8350e-01, -3.7098e-01,  3.2868e-01,\n",
       "         -5.8160e-01, -5.7744e-01,  4.4989e-01,  2.8441e-01,  6.7432e-01,\n",
       "          4.9926e-01, -4.1829e-01,  3.9705e-01, -9.4762e-01,  6.5091e-01,\n",
       "         -3.8231e-01, -9.8818e-01, -6.8914e-01, -9.8749e-01,  6.9904e-01,\n",
       "         -2.5553e-01, -7.3696e-02,  9.6076e-01, -1.7171e-01,  3.9838e-01,\n",
       "         -3.7258e-02, -8.8712e-01, -1.0000e+00, -7.2306e-01, -5.0966e-01,\n",
       "          1.4767e-02, -3.7365e-01, -9.7566e-01, -9.6043e-01,  5.9699e-01,\n",
       "          9.5314e-01,  1.9874e-01,  9.9977e-01, -2.7908e-01,  9.4672e-01,\n",
       "         -3.3948e-01, -5.3136e-01,  6.5447e-01, -5.1037e-01,  6.5431e-01,\n",
       "          2.7234e-01, -6.0505e-01,  3.2160e-01, -4.1222e-01,  3.1424e-01,\n",
       "         -5.7538e-01, -2.2463e-01, -7.0221e-01, -9.2879e-01, -3.5967e-01,\n",
       "          9.3966e-01, -3.5980e-01, -8.9464e-01,  4.1169e-02, -2.9289e-01,\n",
       "         -4.8437e-01,  8.0233e-01,  7.0463e-01,  3.4523e-01, -3.5345e-01,\n",
       "          4.6732e-01,  1.5790e-01,  5.7260e-01, -8.1918e-01, -8.5360e-02,\n",
       "          4.8865e-01, -3.3043e-01, -7.2627e-01, -9.8034e-01, -3.2782e-01,\n",
       "          3.8211e-01,  9.9082e-01,  6.9720e-01,  3.5326e-01,  7.9888e-01,\n",
       "         -3.5396e-01,  7.0598e-01, -9.5566e-01,  9.8248e-01, -1.6516e-01,\n",
       "          3.1800e-01, -2.9462e-01,  7.9500e-02, -8.9241e-01, -1.4908e-02,\n",
       "          8.2734e-01, -6.6565e-01, -8.2813e-01, -1.3473e-01, -5.1852e-01,\n",
       "         -3.2647e-01, -6.7875e-01,  4.8816e-01, -2.7274e-01, -3.1946e-01,\n",
       "         -5.0991e-02,  9.2465e-01,  9.6745e-01,  8.1830e-01,  1.0860e-01,\n",
       "          6.6007e-01, -8.8423e-01, -5.4591e-01,  1.7255e-01,  1.8118e-01,\n",
       "          1.4565e-01,  9.9305e-01, -4.9685e-01, -2.0920e-02, -9.4224e-01,\n",
       "         -9.8813e-01, -1.0052e-01, -9.1803e-01, -2.0973e-01, -6.9539e-01,\n",
       "          6.6378e-01,  3.6460e-02,  4.2551e-01,  4.6597e-01, -9.7786e-01,\n",
       "         -7.9255e-01,  4.8108e-01, -4.8504e-01,  4.5980e-01, -3.6203e-01,\n",
       "          8.9792e-01,  8.8865e-01, -6.8214e-01,  7.8243e-01,  9.2307e-01,\n",
       "         -7.9036e-01, -7.5975e-01,  7.9957e-01, -3.0607e-01,  9.0757e-01,\n",
       "         -6.7049e-01,  9.8390e-01,  8.9578e-01,  8.2497e-01, -9.1931e-01,\n",
       "         -6.6122e-01, -8.8202e-01, -5.7177e-01, -3.1013e-02, -9.9996e-02,\n",
       "          8.3277e-01,  6.7709e-01,  3.8950e-01,  6.1998e-01, -6.0270e-01,\n",
       "          9.9701e-01, -9.0210e-01, -9.6322e-01,  2.5136e-01, -2.1376e-01,\n",
       "         -9.9234e-01,  7.4289e-01,  1.8392e-01,  1.1913e-01, -4.3290e-01,\n",
       "         -6.0073e-01, -9.6640e-01,  8.7827e-01,  8.8137e-02,  9.7846e-01,\n",
       "         -2.0854e-01, -9.2916e-01, -6.2472e-01, -9.0833e-01, -7.1317e-02,\n",
       "         -2.6346e-01, -3.1908e-01, -5.6951e-02, -9.5426e-01,  5.1113e-01,\n",
       "          6.2914e-01,  5.8248e-01, -6.2497e-01,  9.9787e-01,  1.0000e+00,\n",
       "          9.7732e-01,  8.6331e-01,  8.3218e-01, -9.9922e-01, -3.3470e-01,\n",
       "          9.9999e-01, -9.9199e-01, -1.0000e+00, -9.2485e-01, -6.6539e-01,\n",
       "          4.2007e-01, -1.0000e+00, -1.8395e-01,  1.4157e-01, -9.1296e-01,\n",
       "          6.1361e-01,  9.7872e-01,  9.8844e-01, -1.0000e+00,  7.8941e-01,\n",
       "          9.4328e-01, -7.3129e-01,  9.6205e-01, -4.0577e-01,  9.6894e-01,\n",
       "          4.2579e-01,  3.3042e-01, -1.6260e-01,  3.3985e-01, -8.7734e-01,\n",
       "         -8.7749e-01, -3.2025e-01, -6.2692e-01,  9.9470e-01,  2.0113e-01,\n",
       "         -7.6265e-01, -8.9095e-01,  4.5765e-01, -1.1170e-01, -2.7171e-01,\n",
       "         -9.6518e-01, -2.2358e-01,  2.9321e-01,  8.3658e-01,  1.5320e-01,\n",
       "          3.1124e-01, -7.0661e-01,  1.5444e-01, -1.1579e-01,  1.1565e-01,\n",
       "          7.2437e-01, -9.0434e-01, -6.2250e-01, -1.6231e-01, -2.2397e-01,\n",
       "         -4.4408e-01, -9.5732e-01,  9.6087e-01, -2.8173e-01,  8.3570e-01,\n",
       "          1.0000e+00,  1.1694e-02, -8.6517e-01,  6.1013e-01,  3.7288e-01,\n",
       "         -3.5747e-01,  1.0000e+00,  7.7149e-01, -9.7904e-01, -6.2001e-01,\n",
       "          4.7582e-01, -4.8517e-01, -7.0330e-01,  9.9909e-01, -2.9013e-01,\n",
       "         -5.8175e-01, -4.1994e-01,  9.7895e-01, -9.9246e-01,  9.8773e-01,\n",
       "         -9.2276e-01, -9.7394e-01,  9.5282e-01,  9.3975e-01, -5.9837e-01,\n",
       "         -5.9801e-01,  5.7848e-02, -5.2901e-01,  2.5808e-01, -9.3666e-01,\n",
       "          7.6502e-01,  5.9316e-01, -1.7273e-01,  9.2090e-01, -8.4073e-01,\n",
       "         -6.9897e-01,  3.2807e-01, -5.2865e-01,  1.9024e-02,  8.2766e-01,\n",
       "          5.4439e-01, -3.1780e-01,  1.5081e-01, -2.2299e-01, -7.3696e-01,\n",
       "         -9.6866e-01,  5.0494e-01,  1.0000e+00, -1.7367e-01,  6.8417e-01,\n",
       "         -4.8321e-01,  1.6141e-02, -2.0553e-01,  4.7183e-01,  5.9134e-01,\n",
       "         -3.9514e-01, -8.0756e-01,  6.5761e-01, -9.6130e-01, -9.8929e-01,\n",
       "          6.3114e-01,  1.8877e-01, -2.6048e-01,  9.9999e-01,  3.8783e-01,\n",
       "          2.0020e-01,  1.2253e-01,  9.7912e-01, -5.6132e-02,  4.3878e-01,\n",
       "          7.6983e-01,  9.8227e-01, -2.6174e-01,  6.7203e-01,  8.4214e-01,\n",
       "         -8.5244e-01, -3.9641e-01, -6.7099e-01, -2.1071e-03, -9.3039e-01,\n",
       "          9.5873e-02, -9.6330e-01,  9.5168e-01,  8.8167e-01,  4.3210e-01,\n",
       "          1.7645e-01,  6.2112e-01,  1.0000e+00, -4.7656e-01,  4.6465e-01,\n",
       "         -2.2668e-01,  7.9418e-01, -9.9921e-01, -8.1075e-01, -3.8438e-01,\n",
       "         -1.0245e-01, -7.6761e-01, -3.9002e-01,  1.6370e-01, -9.6325e-01,\n",
       "          7.4729e-01,  4.9925e-01, -9.8438e-01, -9.8703e-01, -1.2963e-01,\n",
       "          8.6523e-01,  1.3536e-01, -9.6948e-01, -7.9575e-01, -6.2059e-01,\n",
       "          6.9537e-01, -2.9319e-01, -9.3400e-01, -4.6006e-02, -3.4808e-01,\n",
       "          4.4821e-01, -1.8078e-01,  6.5599e-01,  7.1450e-01,  6.5372e-01,\n",
       "         -3.7284e-01,  7.5090e-02,  3.5957e-02, -7.9178e-01,  9.0225e-01,\n",
       "         -8.4294e-01, -8.8500e-01, -2.1701e-01,  1.0000e+00, -5.1404e-01,\n",
       "          8.6067e-01,  7.6103e-01,  7.5038e-01, -1.9677e-01,  3.3790e-01,\n",
       "          8.1730e-01,  2.8285e-01, -6.2419e-01, -8.2984e-01, -4.9117e-01,\n",
       "         -4.2578e-01,  7.0437e-01,  4.5792e-01,  5.7448e-01,  7.9598e-01,\n",
       "          5.2678e-01,  2.5388e-01,  5.1460e-02,  8.7363e-02,  9.9936e-01,\n",
       "         -2.5998e-01, -2.0969e-01, -3.8086e-01, -1.6119e-01, -3.3271e-01,\n",
       "         -3.2919e-01,  1.0000e+00,  3.3527e-01,  2.7200e-01, -9.9146e-01,\n",
       "         -8.1287e-01, -8.8898e-01,  1.0000e+00,  8.4687e-01, -7.6569e-01,\n",
       "          6.9585e-01,  4.9024e-01, -2.2047e-01,  8.2525e-01, -1.4690e-01,\n",
       "         -2.8037e-01,  2.3962e-01,  1.2581e-01,  9.6004e-01, -5.8514e-01,\n",
       "         -9.7034e-01, -5.4042e-01,  4.3125e-01, -9.6363e-01,  9.9954e-01,\n",
       "         -5.4816e-01, -2.9223e-01, -3.2528e-01, -2.3122e-01,  2.3152e-01,\n",
       "         -2.4540e-02, -9.8148e-01, -3.3816e-01,  1.9600e-01,  9.6416e-01,\n",
       "          2.0182e-01, -6.6166e-01, -8.7706e-01,  5.6432e-01,  7.2920e-01,\n",
       "         -8.6311e-01, -9.3263e-01,  9.6466e-01, -9.7604e-01,  6.4443e-01,\n",
       "          1.0000e+00,  4.7184e-01,  3.3418e-03,  1.7753e-01, -5.6906e-01,\n",
       "          3.7255e-01,  1.2253e-02,  7.6714e-01, -9.5697e-01, -3.4303e-01,\n",
       "         -1.1846e-01,  2.8489e-01, -2.6771e-01, -1.4249e-01,  5.9825e-01,\n",
       "          1.9716e-01, -6.0985e-01, -6.1566e-01, -8.6963e-02,  4.6226e-01,\n",
       "          8.2591e-01, -2.2250e-01, -1.1886e-01,  1.9992e-01, -1.6166e-01,\n",
       "         -8.8493e-01, -3.7628e-01, -3.6924e-01, -9.9997e-01,  5.5691e-01,\n",
       "         -1.0000e+00,  1.9304e-01,  1.4840e-01, -3.5551e-01,  7.8394e-01,\n",
       "          4.2455e-01,  6.0377e-01, -7.6019e-01, -7.7753e-01,  4.8884e-01,\n",
       "          7.5103e-01, -2.8853e-01, -4.7380e-01, -7.2852e-01,  2.1314e-01,\n",
       "         -1.0693e-01,  1.7829e-01, -5.3022e-01,  7.3532e-01, -2.3852e-01,\n",
       "          1.0000e+00,  7.0165e-02, -7.6154e-01, -9.7364e-01,  1.9735e-01,\n",
       "         -2.8010e-01,  1.0000e+00, -9.1112e-01, -9.4305e-01,  4.2815e-01,\n",
       "         -7.0474e-01, -8.3413e-01,  3.4974e-01,  4.3241e-02, -7.3493e-01,\n",
       "         -8.8626e-01,  9.2227e-01,  8.6393e-01, -6.7321e-01,  6.1537e-01,\n",
       "         -2.4155e-01, -6.1657e-01,  5.8356e-02,  7.3148e-01,  9.8882e-01,\n",
       "          2.2489e-01,  9.1832e-01,  2.5694e-01, -4.3075e-01,  9.7097e-01,\n",
       "          2.8420e-01,  3.9573e-01,  8.6291e-02,  1.0000e+00,  2.8949e-01,\n",
       "         -9.0262e-01,  1.7504e-01, -9.8213e-01, -1.7293e-01, -9.5042e-01,\n",
       "          3.7058e-01,  1.6708e-01,  9.0672e-01, -1.6451e-01,  9.6151e-01,\n",
       "         -6.8494e-01,  3.8608e-02, -4.8247e-01, -4.8278e-01,  3.3217e-01,\n",
       "         -9.1821e-01, -9.8462e-01, -9.8392e-01,  5.8322e-01, -5.1318e-01,\n",
       "          6.8306e-04,  2.9014e-01,  1.0678e-01,  3.8164e-01,  3.8321e-01,\n",
       "         -1.0000e+00,  9.2858e-01,  4.7178e-01,  8.0251e-01,  9.6329e-01,\n",
       "          5.9357e-01,  4.7089e-01,  2.8605e-01, -9.8574e-01, -9.7072e-01,\n",
       "         -3.1685e-01, -3.3350e-01,  7.7613e-01,  7.0710e-01,  9.0609e-01,\n",
       "          4.6478e-01, -5.1407e-01, -3.1299e-01, -4.4492e-01, -7.0838e-01,\n",
       "         -9.9145e-01,  5.0294e-01, -5.2528e-01, -9.5645e-01,  9.6445e-01,\n",
       "         -3.7637e-01, -2.6695e-01,  1.8161e-02, -6.6221e-01,  8.9176e-01,\n",
       "          7.3875e-01,  4.3070e-01,  1.2453e-01,  4.0509e-01,  8.7199e-01,\n",
       "          9.3845e-01,  9.8540e-01, -8.1483e-01,  7.1362e-01, -6.3462e-01,\n",
       "          3.7569e-01,  6.5583e-01, -9.1874e-01,  1.5989e-01,  3.2920e-01,\n",
       "         -3.2760e-01,  2.4161e-01, -2.6069e-01, -9.6291e-01,  6.2392e-01,\n",
       "         -3.4098e-01,  5.5989e-01, -3.7559e-01,  9.9826e-02, -3.5321e-01,\n",
       "         -2.5586e-01, -7.5374e-01, -7.4421e-01,  7.0692e-01,  5.6265e-01,\n",
       "          9.0162e-01,  7.3443e-01, -2.0422e-02, -8.0198e-01, -8.9805e-02,\n",
       "         -7.0449e-01, -9.4412e-01,  9.1454e-01, -9.0367e-02, -2.1050e-01,\n",
       "          7.0062e-01, -3.2161e-02,  7.9639e-01,  3.6545e-02, -4.0366e-01,\n",
       "         -2.9155e-01, -7.3576e-01,  8.5368e-01, -5.2065e-01, -5.2799e-01,\n",
       "         -6.5904e-01,  6.0108e-01,  3.7854e-01,  9.9992e-01, -6.2717e-01,\n",
       "         -8.7334e-01, -3.7129e-01, -4.0878e-01,  4.0354e-01, -5.1467e-01,\n",
       "         -1.0000e+00,  4.3918e-01, -1.8497e-01,  6.5464e-01, -7.2885e-01,\n",
       "          7.3107e-01, -6.6488e-01, -9.6227e-01, -2.5233e-01,  3.6046e-01,\n",
       "          6.3349e-01, -5.4167e-01, -6.8578e-01,  6.5271e-01, -2.5380e-01,\n",
       "          9.6249e-01,  8.4247e-01, -1.4070e-01,  3.3277e-01,  7.3931e-01,\n",
       "         -6.4720e-01, -7.0183e-01,  9.2175e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb7a18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector.last_hidden_state.shape\n",
    "# [1: 문서(문장) 개수, 5:토큰 수, 768: embedding vector의 차원 수]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a208bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1045, 2572, 1037, 2879, 1012, 102]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토크나이저 \n",
    "t = tokenizer.encode(\"I am a boy.\") # 토큰 아이디들만 리턴\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80876df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] i am a boy. [SEP]'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49c920e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 2572, 1037, 2879]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별 토큰 확인\n",
    "tokenizer.convert_tokens_to_ids(\"am\")\n",
    "tokenizer.convert_tokens_to_ids([\"I\", \"am\", \"a\", \"boy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "772dd775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'am'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(2572)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a02d44-7271-4db4-b8c0-7c14037dce3a",
   "metadata": {},
   "source": [
    "## kcbert\n",
    "- BERT 모델을 한글 텍스트로 학습 시킨 Pretrained model.\n",
    "    - BERT는 Transformer의 Encoder 부분을 이용해 구현된 언어모델\n",
    "    - https://arxiv.org/abs/1810.04805 \n",
    "- https://huggingface.co/beomi/kcbert-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0af872e-410e-4a3c-8ec3-2b1e1a680ad6",
   "metadata": {},
   "source": [
    "### 토크나이저 모델 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2518bce-6fd0-4512-9d59-0def0653095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_id = \"beomi/kcbert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28171f1e-7588-4583-b027-224ab6e09c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(300, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5087a1-04bb-4b36-912f-c1c5bdd77101",
   "metadata": {},
   "source": [
    "### 입력값 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d78342de-1a9c-4b70-a997-c7bca15432ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"안녕\"\n",
    "    \"Hugging Face는 인공지능(AI)과 자연어 처리(NLP) 분야에서 혁신적인 도구와 모델을 제공하는 AI 스타트업이다.\",\n",
    "    \"2016년에 설립된 이 회사는 주로 오픈소스 라이브러리와 사전 학습된 NLP 모델을 제공을 제공한다.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a918a72c-9240-4173-bd94-a734ee5e946e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 19017, 5121, 4223, 4403, 4403, 18940, 39, 4243, 4773, 4226, 4008, 14583, 25061, 11, 22502, 12, 321, 10459, 4071, 9810, 11, 47, 4450, 4579, 12, 16029, 7971, 13064, 8097, 867, 4228, 4196, 16505, 4027, 13248, 7966, 22502, 12296, 4104, 22192, 4020, 17, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = tokenizer(sentences[0])\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ac67024-c95b-48cf-8329-ae3b59f5a04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.keys()\n",
    "# 기본적으로 input_ids, attention_mask는 준다\n",
    "# input_ids: 토큰 id들\n",
    "# attention_mask: input_ids의 개별 토큰들이 실제 값인지 [PAD]인지 구분. (1: 실제 토큰, 0: 패딩)\n",
    "# 이 모델은 token_type_ids를 더 준 것\n",
    "# token_type_ids: 입력이 두 개 문서로 구성된 경우 (question-answering: Question, Context)\n",
    "#                 각 토큰이 몇 번째 문서인지 구분하기 위한 값이다.\n",
    "# input_ids:        [q, q, q, q, c, c, c]\n",
    "# token_type_ids:   [0, 0, 0, 0, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fee1ddf2-e148-43d6-ac7d-30dfa414aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = tokenizer(\n",
    "    sentences, # 토큰화할 문서들\n",
    "    max_length=10, # padding/truncation의 기준 길이 지정\n",
    "    padding=True, # 패딩 추가. default: batch에서 가장 긴 sequence에 맞춰서 패딩. \n",
    "                                        # max_length가 설정된 경우는 max_length에 맞춘다.\n",
    "    truncation=True, # max_length 보다 개수가 많은 seq일 경우 max_length에 맞춰 뒤에 토큰을 잘라낸다.\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b252e616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2, 19017,  5121,  4223,  4403,  4403, 18940,    39,  4243,     3],\n",
       "        [    2, 26182,  4113, 20684,  4130,  2451, 22088, 20002, 15999,     3]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b905f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "99c60620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list[\"token_type_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52498095-7fb8-4da1-9103-d22b10e9ef43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list[\"input_ids\"][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d6f557",
   "metadata": {},
   "source": [
    "truncation 된 거임. 10개로 잘라냄"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19acd0fe-5952-4ee6-97ee-e4fcf41ec093",
   "metadata": {},
   "source": [
    "### BERT 모델을 이용해 context vector 추출\n",
    "#### Model 추론결과\n",
    "- **last_hidden_state**\n",
    "    - 모든 token들에 대한 feature\n",
    "    - 출력이 **many**인 작업에 사용한다.\n",
    "- **pooler_output**\n",
    "    - 입력 문장, 텍스트에 대한 context vector 이다.\n",
    "    - 이 값은 **문장을 입력받아 처리하는 task**(ex: 문서분류-감정분석,문장카테고리분류, 문장유사도 분석)의 입력으로 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "42e0659e-22b0-47b0-96e6-037d9befad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "07251f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "98f7fc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"pooler_output\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf92817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a206af7-a0c1-4025-804d-8012b9eae71c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
