{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3fa1505-5df4-415a-b490-73573300ae62",
   "metadata": {},
   "source": [
    "# Gensim 패키지\n",
    "- Python으로 작성된 오픈 소스 라이브러리로, 자연어 처리와 관련된 다양한 기능을 제공한다.\n",
    "- 주요 기능\n",
    "    - **Word Embeddings**\n",
    "        - word2vec, fastext, doc2vec 등 다양한 word embedding 모델을 제공\n",
    "    - **토픽 모델링 (Topic Modeling)**\n",
    "        - LDA등 문장의 주제를 파악하는 모델 제공\n",
    "    - **텍스트/word 유사도 계산**\n",
    "    - **문서 군집화**\n",
    "        - 비슷한 주제의 문서들을 군집화.\n",
    "    - 다양한 dataset과 pretrained model 제공\n",
    "        - https://github.com/piskvorky/gensim-data\n",
    "- https://radimrehurek.com/gensim/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61e9bfe",
   "metadata": {},
   "source": [
    "요즘은 Gensim보다는 Hugging Face 많이 씁니다. 그렇게 중요한 패키지는 아니지만, word2vec을 실습해보자는 의미에서 가볍게 보아요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb22fe8-39a2-493b-90d1-6eb59884bfbe",
   "metadata": {},
   "source": [
    "## 설치\n",
    "- `pip install gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f29179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\anaconda3\\envs\\dl\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\anaconda3\\envs\\dl\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\anaconda3\\envs\\dl\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\anaconda3\\envs\\dl\\lib\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\anaconda3\\envs\\dl\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf6c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22013f4-94ed-4cba-8d86-31836ba16af1",
   "metadata": {},
   "source": [
    "# Word2Vec 학습\n",
    "\n",
    "- gensim.models.Word2Vec\n",
    "- 주요 파라미터\n",
    "    - sentences\n",
    "        -  학습에 사용할 문서의 리스트. 각 문서의 단어들을 리스트로 묶고 그 문서들을 리스트로 묶은 중첩 리스트.\n",
    "        - 예시: \\[\\['word1', 'word2', 'word3'], \\['word4', 'word5']]\n",
    "    - vector_size\n",
    "        -  embedding vector 크기. 기본값: 100\n",
    "    - window\n",
    "        -  context window 크기. 중심단어를 기준으로 좌우 몇개의 단어를 확인하는지 크기. 기본값: 5\n",
    "    - min_count\n",
    "        - 이 설정보다 낮은 빈도로 등장하는 단어는 무시한다. 데이터 노이즈를 줄이는데 도움이된다. 기본값: 5\n",
    "    - sg\n",
    "        - 모델 아키텍처 결정.\n",
    "        - `0`: CBOW, `1`: Skip-gram. 기본값: 0\n",
    "    - epochs\n",
    "        - epochs 수 설정. 기본값: 5\n",
    "    - alpha\n",
    "        - initial leaning rate. 기본값: 0.025\n",
    "    - min_alpha\n",
    "        - 최소 learning rate. 기본값: 0.0001\n",
    "        - epoch 마다 learning rate를 alpha 에서 min_alpha 까지 선형적으로 줄여나간다.\n",
    "    - workers\n",
    "        -  사용 Thread 수. (= cpu의 개수) 기본값: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f350467-b0c2-46fa-b1f7-e2c57a4bf439",
   "metadata": {},
   "source": [
    "## 학습(Train)\n",
    "1. Word2Vec 의 initializer에 sentences를 넣어 한번에 학습한다.\n",
    "2. Word2Vec 클래스에 학습 설정을 하고 `train()` 메소드를 이용해 학습한다.\n",
    "    - epoch 단위로 작업을 할 경우 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903930ed",
   "metadata": {},
   "source": [
    "epoch을 내가 지정할 수 있다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a02a4e9-2d24-4ede-8395-0482661809a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 텍스트 데이터\n",
    "sentences = [\n",
    "    \"Natural language processing is an exciting field of study\",\n",
    "    \"Word embeddings are a type of word representation\",\n",
    "    \"Gensim is a powerful library for text processing\",\n",
    "    \"Word2Vec creates vector representations of words\", \n",
    "    \"Gensim runs on Linux, Windows and OS X, as well as any other platform that supports Python and NumPy.\"\n",
    "    \"All Gensim source code is hosted on Github under the GNU LGPL license, maintained by its open source community.\",\n",
    "    \"For commercial arrangements, see Business Support.\",\n",
    "    \"Gensim can process arbitrarily large corpora, using data-streamed algorithms.\",\n",
    "    \"There are no \\\"dataset must fit in RAM\\\" limitations.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f006025",
   "metadata": {},
   "source": [
    "토큰화하는 건 우리가 해야 함. 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b455f3f-def9-487e-a3a4-f9563562e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "def tokenizer(docs):\n",
    "    # 소문자로 모두 변환\n",
    "    # 알파벳, 숫자, _,를 제외한 모든 문자들을 제거\n",
    "    # 단어(어절) 단위 토큰화\n",
    "    return [nltk.word_tokenize(re.sub(r\"[^\\w\\s]\", \"\", doc.lower())) for doc in sentences]\n",
    "\n",
    "# [^\\w\\s] - \\w(문자) '또는' \\s(공백 문자)를 제외한 나머지(^)들을 찾아라.\n",
    "# 공백 문자 \\s를 포함하지 않으면: 공백 문자도 없어져버림.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f3a73dc-943f-4baa-a072-c9b30ea482e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'is',\n",
       "  'an',\n",
       "  'exciting',\n",
       "  'field',\n",
       "  'of',\n",
       "  'study'],\n",
       " ['word', 'embeddings', 'are', 'a', 'type', 'of', 'word', 'representation'],\n",
       " ['gensim', 'is', 'a', 'powerful', 'library', 'for', 'text', 'processing'],\n",
       " ['word2vec', 'creates', 'vector', 'representations', 'of', 'words'],\n",
       " ['gensim',\n",
       "  'runs',\n",
       "  'on',\n",
       "  'linux',\n",
       "  'windows',\n",
       "  'and',\n",
       "  'os',\n",
       "  'x',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'any',\n",
       "  'other',\n",
       "  'platform',\n",
       "  'that',\n",
       "  'supports',\n",
       "  'python',\n",
       "  'and',\n",
       "  'numpyall',\n",
       "  'gensim',\n",
       "  'source',\n",
       "  'code',\n",
       "  'is',\n",
       "  'hosted',\n",
       "  'on',\n",
       "  'github',\n",
       "  'under',\n",
       "  'the',\n",
       "  'gnu',\n",
       "  'lgpl',\n",
       "  'license',\n",
       "  'maintained',\n",
       "  'by',\n",
       "  'its',\n",
       "  'open',\n",
       "  'source',\n",
       "  'community'],\n",
       " ['for', 'commercial', 'arrangements', 'see', 'business', 'support'],\n",
       " ['gensim',\n",
       "  'can',\n",
       "  'process',\n",
       "  'arbitrarily',\n",
       "  'large',\n",
       "  'corpora',\n",
       "  'using',\n",
       "  'datastreamed',\n",
       "  'algorithms'],\n",
       " ['there', 'are', 'no', 'dataset', 'must', 'fit', 'in', 'ram', 'limitations']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# [re.sub(r\"[^\\w]\", \"\", doc.lower()) for doc in sentences] # 문장 전처리\n",
    " # 토큰화\n",
    "tokens = tokenizer(sentences)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61df707b",
   "metadata": {},
   "source": [
    "문장별로 토큰 리스트를 저장한 게 리스트로 묶여있는 거임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c33d8473-e106-4d7e-b115-b0072833efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 - train\n",
    "# Word2Vec 객체를 생성: 학습 데이터, epoch을 지정 -> 객체 생성할 때 모델을 학습까지! 하긋ㅂ 결과 모델을 반환한다. \n",
    "from gensim.models import Word2Vec\n",
    "model1 = Word2Vec(\n",
    "    sentences= tokens, # 학습 데이터\n",
    "    vector_size=10, # embedding vector의 차원 (한 개 단어에서 몇 개 feature를 추출할지)\n",
    "    window=2, # window size 설정. 주변 단어의 개수\n",
    "    min_count=1, # 최소 출연 빈도수. 얘가 있어야 vocab을 제대로 만들어요!\n",
    "    epochs=10,\n",
    "    workers=3 # 병렬 처리 개수. cpu 개수에 따라 달라진다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "395fd7bb-3e14-49c2-9abe-5f3663f481a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.cpu_count() # 현재 컴퓨터에서 병렬로 처리할 수 있는 최대 개수, 코어가 몇 개 있는지\n",
    "# workers에 os.cpu_count()를 넣으면 -> 컴퓨터 자원을 모두 다 쓰겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd2bf12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 epoch loss: 156.24295043945312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodel2.train(\\n        tokens, # 학습 데이터\\n        total_examples=model2.corpus_count, # 학습 데이터(문서) 개수\\n        epochs=10, \\n    )\\n위와 같은 결과임.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습데이터, epoch을 설정하지 않음 => 학습 안 된 모델을 반환\n",
    "model2 = Word2Vec(vector_size=10, window=2, min_count=1, workers=os.cpu_count())\n",
    "# model에 vocab을 설정.\n",
    "model2.build_vocab(tokens)\n",
    "# 학습\n",
    "epoch=10\n",
    "\n",
    "# 1 epoch 단위로 작성하는 경우\n",
    "for e in range(epoch):\n",
    "    model2.train(\n",
    "        tokens, # 학습 데이터\n",
    "        total_examples=model2.corpus_count, # 학습 데이터(문서) 개수\n",
    "        epochs=1, \n",
    "        compute_loss = True # 학습이 끝나면 loss 계산\n",
    "        # com_loss=True 해줘야 loss를 가져올 수 있다. \n",
    "    )\n",
    "loss = model2.get_latest_training_loss() # train()시 계산된 loss를 조회\n",
    "print(f\"{e} epoch loss: {loss}\")\n",
    "'''\n",
    "model2.train(\n",
    "        tokens, # 학습 데이터\n",
    "        total_examples=model2.corpus_count, # 학습 데이터(문서) 개수\n",
    "        epochs=10, \n",
    "    )\n",
    "위와 같은 결과임.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7fe805-022b-4e1a-b0ea-8e5bc692fa75",
   "metadata": {},
   "source": [
    "## 학습 후 결과 조회\n",
    "\n",
    "- **KeyedVectors 조회**\n",
    "    - KeyedVectors는 **단어와 vector를 매핑한 객체**로 embedding vector를 이용한 다양한 조회를 지원한다.\n",
    "    - model.wv 로 조회해서 사용.\n",
    "- **Embedding Vector 조회**\n",
    "  - model.wv.vectors\n",
    "- **단어 목록 조회**\n",
    "    - model.wv.index_to_key, model.wv.key_to_index\n",
    "- **단어 벡터 조회**\n",
    "    - model.wv[word]: 특정 단어의 vector반환\n",
    "- **Vocab에 대상 단어가 있는지 확인**\n",
    "    - \"대상단어\" in model.wv\n",
    "- **유사단어들 찾기**\n",
    "    - model.wv.most_similar(word)\n",
    "- **단어간 유사도 비교**\n",
    "    - model.wv.similarity(word1, word2)\n",
    "- 유사도를 계산할 때 **코사인 유사도(Cosine Similarity)** 를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba473d91",
   "metadata": {},
   "source": [
    "> # 코사인 유사도\n",
    "> - 두 벡터 간의 유사성을 측정하는 중요한 방법 중 하나.\n",
    "> - 코사인 유사도는 두 벡터 간의 코사인 각도를 이용하여 유사도를 계산한다. 이때 벡터의 **크기는 결과에 영향을 미치지 않고, 오직 방향만이 중요**하다.\n",
    "> ## 공식\n",
    "> \n",
    "> $$ similarity = cos(\\theta) = \\frac{A⋅B}{||A||\\ ||B||} = \\frac{\\sum_{i=1}^{n}{A_i×B_i}}{\\sqrt{\\sum_{i=1}^{n}(A_i)^2}×\\sqrt{\\sum_{i=1}^{n}(B_i)^2}} $$\n",
    "> \n",
    "> ## 결과 해석\n",
    "> \n",
    "> - **값의 범위**: -1에서 1 사이의 값을 가집니다\n",
    ">   - 1: 두 벡터가 완전히 동일한 방향 (0도의 cosine 값)\n",
    ">   - 0: 두 벡터가 직교 (90도의 cosine 값)\n",
    ">   - -1: 두 벡터가 정반대 방향 (180도의 cosine 값)\n",
    "> \n",
    "> ![cosine_similarity](figures/gensim_consin_sim.png)\n",
    ">\n",
    "> ## Python 코사인 유사도 계산\n",
    "> ```python\n",
    "> from numpy import dot\n",
    "> from numpy.linalg import norm\n",
    "> \n",
    "> def cosine_similarity(A, B):\n",
    ">     return dot(A, B)/(norm(A)*norm(B))\n",
    "> ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dc4479",
   "metadata": {},
   "source": [
    "값의 크기가 아닌 **방향**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c5d0e0b-0d18-40ac-91c4-11e9114acbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1a8e1345760>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv # KeyedVectors -> 토큰 - embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36df1892-1804-4f23-a396-b52f82238d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gensim',\n",
       " 'is',\n",
       " 'of',\n",
       " 'for',\n",
       " 'processing',\n",
       " 'source',\n",
       " 'as',\n",
       " 'on',\n",
       " 'word',\n",
       " 'are',\n",
       " 'a',\n",
       " 'and',\n",
       " 'words',\n",
       " 'runs',\n",
       " 'linux',\n",
       " 'os',\n",
       " 'windows',\n",
       " 'vector',\n",
       " 'x',\n",
       " 'well',\n",
       " 'any',\n",
       " 'representations',\n",
       " 'limitations',\n",
       " 'creates',\n",
       " 'word2vec',\n",
       " 'text',\n",
       " 'platform',\n",
       " 'library',\n",
       " 'powerful',\n",
       " 'representation',\n",
       " 'type',\n",
       " 'embeddings',\n",
       " 'study',\n",
       " 'field',\n",
       " 'exciting',\n",
       " 'an',\n",
       " 'language',\n",
       " 'other',\n",
       " 'that',\n",
       " 'ram',\n",
       " 'see',\n",
       " 'support',\n",
       " 'can',\n",
       " 'process',\n",
       " 'arbitrarily',\n",
       " 'large',\n",
       " 'corpora',\n",
       " 'using',\n",
       " 'datastreamed',\n",
       " 'algorithms',\n",
       " 'there',\n",
       " 'no',\n",
       " 'dataset',\n",
       " 'must',\n",
       " 'fit',\n",
       " 'in',\n",
       " 'business',\n",
       " 'arrangements',\n",
       " 'supports',\n",
       " 'commercial',\n",
       " 'python',\n",
       " 'numpyall',\n",
       " 'code',\n",
       " 'hosted',\n",
       " 'github',\n",
       " 'under',\n",
       " 'the',\n",
       " 'gnu',\n",
       " 'lgpl',\n",
       " 'license',\n",
       " 'maintained',\n",
       " 'by',\n",
       " 'its',\n",
       " 'open',\n",
       " 'community',\n",
       " 'natural']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv.index_to_key # vocab: token_id -> token (단어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9607cc94-67cf-4a87-8a42-ab88683cd514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gensim': 0,\n",
       " 'is': 1,\n",
       " 'of': 2,\n",
       " 'for': 3,\n",
       " 'processing': 4,\n",
       " 'source': 5,\n",
       " 'as': 6,\n",
       " 'on': 7,\n",
       " 'word': 8,\n",
       " 'are': 9,\n",
       " 'a': 10,\n",
       " 'and': 11,\n",
       " 'words': 12,\n",
       " 'runs': 13,\n",
       " 'linux': 14,\n",
       " 'os': 15,\n",
       " 'windows': 16,\n",
       " 'vector': 17,\n",
       " 'x': 18,\n",
       " 'well': 19,\n",
       " 'any': 20,\n",
       " 'representations': 21,\n",
       " 'limitations': 22,\n",
       " 'creates': 23,\n",
       " 'word2vec': 24,\n",
       " 'text': 25,\n",
       " 'platform': 26,\n",
       " 'library': 27,\n",
       " 'powerful': 28,\n",
       " 'representation': 29,\n",
       " 'type': 30,\n",
       " 'embeddings': 31,\n",
       " 'study': 32,\n",
       " 'field': 33,\n",
       " 'exciting': 34,\n",
       " 'an': 35,\n",
       " 'language': 36,\n",
       " 'other': 37,\n",
       " 'that': 38,\n",
       " 'ram': 39,\n",
       " 'see': 40,\n",
       " 'support': 41,\n",
       " 'can': 42,\n",
       " 'process': 43,\n",
       " 'arbitrarily': 44,\n",
       " 'large': 45,\n",
       " 'corpora': 46,\n",
       " 'using': 47,\n",
       " 'datastreamed': 48,\n",
       " 'algorithms': 49,\n",
       " 'there': 50,\n",
       " 'no': 51,\n",
       " 'dataset': 52,\n",
       " 'must': 53,\n",
       " 'fit': 54,\n",
       " 'in': 55,\n",
       " 'business': 56,\n",
       " 'arrangements': 57,\n",
       " 'supports': 58,\n",
       " 'commercial': 59,\n",
       " 'python': 60,\n",
       " 'numpyall': 61,\n",
       " 'code': 62,\n",
       " 'hosted': 63,\n",
       " 'github': 64,\n",
       " 'under': 65,\n",
       " 'the': 66,\n",
       " 'gnu': 67,\n",
       " 'lgpl': 68,\n",
       " 'license': 69,\n",
       " 'maintained': 70,\n",
       " 'by': 71,\n",
       " 'its': 72,\n",
       " 'open': 73,\n",
       " 'community': 74,\n",
       " 'natural': 75}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c3c06ac-5bb3-4a2f-b0ac-d1aa0c747f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00530078,  0.00215998,  0.0511257 ,  0.08994552, -0.0929675 ,\n",
       "       -0.07124555,  0.06510045,  0.08978292, -0.05092729, -0.0380263 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv['gensim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d50a3150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in 연산자 -> vocab에 특정 단어가 있는지 여부\n",
    "# model1.wv['안녕'] # '안녕'은 토큰에 없음 -> KeyError\n",
    "'안녕' in model1.wv  # False\n",
    "'gensim' in model1.wv  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95ee9d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "없는 단어입니다.\n"
     ]
    }
   ],
   "source": [
    "word = '안녕'\n",
    "if word in model1.wv:\n",
    "    print(model1.wv[word])\n",
    "else:\n",
    "    print(\"없는 단어입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1c9e2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('numpyall', 0.7189716696739197),\n",
       " ('study', 0.7138967514038086),\n",
       " ('that', 0.6710396409034729),\n",
       " ('can', 0.6415793299674988),\n",
       " ('datastreamed', 0.5988761186599731),\n",
       " ('is', 0.5452057123184204),\n",
       " ('other', 0.5355265140533447),\n",
       " ('maintained', 0.5195195078849792),\n",
       " ('representations', 0.5130788087844849),\n",
       " ('in', 0.507987380027771)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사도 검사\n",
    "model1.wv.most_similar(\"gensim\") # 'gensim'과 가장 유사한 단어를 순서대로 10개를 반환.\n",
    "# (단어, 유사도) 유사도 -1 ~ 1 (1에 가까울 수록 유사, -1에 가까울 수록 반대)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb595e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('numpyall', 0.7189716696739197),\n",
       " ('study', 0.7138967514038086),\n",
       " ('that', 0.6710396409034729)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv.most_similar(\"gensim\", topn=3) # 상위 3개만 볼래요~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d55efe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71389675"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 간의 유사도\n",
    "model1.wv.similarity(\"gensim\", \"study\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52de32ef-2dc7-49a6-b829-68b14f797267",
   "metadata": {},
   "source": [
    "## 모델 저장 및 로딩\n",
    "\n",
    "### 모델 저장, 로딩\n",
    "- `model.save('저장파일 경로')`\n",
    "  - gensim 자체 포맷으로 저장된다.\n",
    "- `gensim.models.Word2Vec.load('저장파일 경로')`\n",
    "  - `model.save()`로 저장된 모델을 Loading한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b9517b7-ee62-4313-a78e-42d5240cb276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "model1.save(\"saved_models/w2v_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1f55800-3dd3-4054-9c07-d48961518099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "load_model = Word2Vec.load(\"saved_models/w2v_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05ef8f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('numpyall', 0.7189716696739197),\n",
       " ('study', 0.7138967514038086),\n",
       " ('that', 0.6710396409034729),\n",
       " ('can', 0.6415793299674988),\n",
       " ('datastreamed', 0.5988761186599731),\n",
       " ('is', 0.5452057123184204),\n",
       " ('other', 0.5355265140533447),\n",
       " ('maintained', 0.5195195078849792),\n",
       " ('representations', 0.5130788087844849),\n",
       " ('in', 0.507987380027771)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model.wv.most_similar(\"gensim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c1e94c",
   "metadata": {},
   "source": [
    "위와 같은 결과가 나옴! 제대로 로드 되었다는 뜻이다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34742583-58b5-40c8-b3ab-a641147cdd07",
   "metadata": {},
   "source": [
    "### Word Embedding Vector만 저장 및 로드\n",
    "- `KeyedVectors` 를 이용해 저장한다.\n",
    "    - `model.wv.save_word2vec_format('저장경로', binary=True|False)`\n",
    "        - binary=True: binary 파일로 저장한다. 용량이 작은 대신 내용확인이 안된다.\n",
    "        - binary=False: csv(공백구분자) 형식 text로 저장한다. 내용을 확인할 수있지만 파일용량이 크다.\n",
    "- `KeyedVectors.load_word2vec_format(\"저장경로\", binary=True|False)`\n",
    "    - 저장시 binary에 맞춰 읽는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9dfab01-5ed0-4749-a585-fb26ba817495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1a8e1345760>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv # KeyedVectors가 반환된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a72063a1-afa5-4c69-b271-982d1f185843",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.wv.save_word2vec_format(\"saved_models/keyedvector.bin\", binary=True)\n",
    "model1.wv.save_word2vec_format(\"saved_models/keyedvector.csv\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1563b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "load_wv_bin = KeyedVectors.load_word2vec_format(\"saved_models/keyedvector.bin\", binary=True)\n",
    "load_wv_csv = KeyedVectors.load_word2vec_format(\"saved_models/keyedvector.csv\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc4f7b0a-8620-4c34-b463-3c186a70c107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('numpyall', 0.7189716696739197),\n",
       " ('study', 0.7138967514038086),\n",
       " ('that', 0.6710396409034729),\n",
       " ('can', 0.6415793299674988),\n",
       " ('datastreamed', 0.5988761186599731),\n",
       " ('is', 0.5452057123184204),\n",
       " ('other', 0.5355265140533447),\n",
       " ('maintained', 0.5195195078849792),\n",
       " ('representations', 0.5130788087844849),\n",
       " ('in', 0.507987380027771)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_wv_bin.most_similar('gensim')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdd71aa",
   "metadata": {},
   "source": [
    "잘 읽어와졌다.. 👍🏼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0bcbb4",
   "metadata": {},
   "source": [
    "transfer learning: 이미 만들어진 것을 가져다 쓴다. 거기다 필요하면 내용 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66b7152-2745-4e30-bc6f-5e417ab25f00",
   "metadata": {},
   "source": [
    "## Pretrained 모델 사용하기\n",
    "- https://github.com/Kyubyong/wordvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a1934c",
   "metadata": {},
   "source": [
    "강사님이 주신 ko_new 파일을 이용합니당."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52eab43d-4df0-44b6-a531-83f66c427996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(\"ko_new.zip\") as zf: # 압축풀 파일 경로\n",
    "    zf.extractall(\"saved_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5622212",
   "metadata": {},
   "source": [
    "extract: 개별 파일을 하나씩 푼다.\n",
    "\n",
    "extractall: 모든 파일을 다 푼다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7907d09e-8fd1-4462-9679-ca182617e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_wv = KeyedVectors.load_word2vec_format(\n",
    "    \"saved_models/ko_new.txt\",\n",
    "    binary=False,\n",
    "    encoding='utf-8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0474f99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('아침', 0.8432559967041016), ('밤', 0.7863156795501709), ('새벽', 0.7520349025726318)]\n"
     ]
    }
   ],
   "source": [
    "word = \"저녁\"\n",
    "result = ko_wv.most_similar(word, topn=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f115fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('코끼리', 0.7047041654586792), ('표범', 0.6993285417556763), ('멧돼지', 0.6985809803009033)]\n"
     ]
    }
   ],
   "source": [
    "word = \"호랑이\"\n",
    "result = ko_wv.most_similar(word, topn=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a6b9cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('비스킷', 0.7836082577705383), ('시럽', 0.7781529426574707), ('초콜릿', 0.7692068815231323)]\n"
     ]
    }
   ],
   "source": [
    "word = \"푸딩\"\n",
    "result = ko_wv.most_similar(word, topn=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb37baa",
   "metadata": {},
   "source": [
    "# 빅카인즈 뉴스 데이터를 이용한 Word2Vec 학습\n",
    "- 빅카인즈\n",
    "    - 한국언론진흥재단에서 운영하는 뉴스빅데이터 분석 서비스 사이트\n",
    "- 빅카인즈에서 특정 분야의 기사들을 수집해서 학습시킨다.\n",
    "    - https://www.bigkinds.or.kr/\n",
    "    - 회원가입 (구글, 네이버, 카카오 계정으로 가입 가능) 후 로그인\n",
    "    - 뉴스분석 > 뉴스검색$\\cdot$분석 클릭\n",
    "    ![word2vec_bigkinds1.png](figures/word2vec_bigkinds1.png)\n",
    "    - 기간, 언론사, 분류, 상세검색 등 검색 조건입력 후 조회\n",
    "    ![word2vec_bigkinds1.png](figures/word2vec_bigkinds2.png)\n",
    "    - 결과 다운로드\n",
    "        - step3 분석결과및 시각화 -> 맨 아래 `엑셀다운로드` 클릭 \n",
    "    ![word2vec_bigkinds1.png](figures/word2vec_bigkinds3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1579978e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\anaconda3\\envs\\dl\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\anaconda3\\envs\\dl\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3d0d2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\dl\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"NewsResult_20250223-20250523.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4771754d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>본문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“내가 재림예수다” 허경영, 구속 송치  ‘대천사’ 칭호 주고 1억 원 챙겨</td>\n",
       "      <td>고가의 영성 상품을 판매하고 신도들을 추행한 혐의를 받는 허경영 국가혁명당 명예 대...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>한미 관세 2차 실무협의 마무리 다음 협의는 대선 이후</td>\n",
       "      <td>미국의 상호관세 및 품목관세 문제를 협의하기 위한 한미 국장급 2차 실무 협의가 마...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>박명수 경기도의원, “강산 4번 바뀌는 동안 안성은 바뀐 것 하나 없다”</td>\n",
       "      <td>경기도의회 박명수 의원(국민의힘, 안성2)은 21일(화) 안성상담소에서 수자원본부로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LS전선 구본규 대표, 베트남서 해저망 희토류 사업 공략</td>\n",
       "      <td>아시아투데이 김한슬 기자 = 구본규 LS전선 대표가 베트남 기업 및 정부 관계자들을...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000만원 내면 ‘대통령대리’ 임명에 체포 면제?  ‘기막힌 허경영의 사기행각’</td>\n",
       "      <td>영적 능력이 있다며 최대 1억원에 달하는 영성상품을 판매하고 신도들을 강제로 추행한...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>아파트 분양가 이래서 비쌌나 한샘 리바트 등 빌트인 가구 담합</td>\n",
       "      <td>한샘, 현대리바트 등 13개 가구업체가 반도건설이 발주한 아파트 특판가구 입찰에서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3815</th>\n",
       "      <td>‘분식회계 채용비리’ 하성용 전 KAI 대표, 징역형 집행유예 확정</td>\n",
       "      <td>수천억원대 분식회계와 채용 비리 의혹 등으로 재판에 넘겨진 하성용 전 한국항공우주산...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3816</th>\n",
       "      <td>“원칙과 소신이 중요” ‘계엄’과 ‘탄핵’ 겪은 한 ‘공인’의 조언</td>\n",
       "      <td>대한민국이 좀처럼 혼돈에서 벗어나지 못하고 있다. 헌법재판소의 윤석열 대통령 탄핵 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3817</th>\n",
       "      <td>트럼프와 머스크의 ‘해고 칼춤’ 미 공무원 1만명 일자리 잃는다</td>\n",
       "      <td>찍힌 기관들 사실상 폐쇄 절차 사법부 ‘일시 중단’ 명령도 무시\\n\\n\\n\\n[주간...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>토지거래허가 풀리자 강남3구 아파트값 평균 8% 상승</td>\n",
       "      <td>아시아투데이 전원준 기자 = 서울 강남 3구(강남 서초 송파구) '국민평형' 아파트...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3819 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 제목  \\\n",
       "0        “내가 재림예수다” 허경영, 구속 송치  ‘대천사’ 칭호 주고 1억 원 챙겨   \n",
       "1                    한미 관세 2차 실무협의 마무리 다음 협의는 대선 이후   \n",
       "2          박명수 경기도의원, “강산 4번 바뀌는 동안 안성은 바뀐 것 하나 없다”   \n",
       "3                   LS전선 구본규 대표, 베트남서 해저망 희토류 사업 공략   \n",
       "4     1000만원 내면 ‘대통령대리’ 임명에 체포 면제?  ‘기막힌 허경영의 사기행각’   \n",
       "...                                             ...   \n",
       "3814             아파트 분양가 이래서 비쌌나 한샘 리바트 등 빌트인 가구 담합   \n",
       "3815          ‘분식회계 채용비리’ 하성용 전 KAI 대표, 징역형 집행유예 확정   \n",
       "3816          “원칙과 소신이 중요” ‘계엄’과 ‘탄핵’ 겪은 한 ‘공인’의 조언   \n",
       "3817            트럼프와 머스크의 ‘해고 칼춤’ 미 공무원 1만명 일자리 잃는다   \n",
       "3818                  토지거래허가 풀리자 강남3구 아파트값 평균 8% 상승   \n",
       "\n",
       "                                                     본문  \n",
       "0     고가의 영성 상품을 판매하고 신도들을 추행한 혐의를 받는 허경영 국가혁명당 명예 대...  \n",
       "1     미국의 상호관세 및 품목관세 문제를 협의하기 위한 한미 국장급 2차 실무 협의가 마...  \n",
       "2     경기도의회 박명수 의원(국민의힘, 안성2)은 21일(화) 안성상담소에서 수자원본부로...  \n",
       "3     아시아투데이 김한슬 기자 = 구본규 LS전선 대표가 베트남 기업 및 정부 관계자들을...  \n",
       "4     영적 능력이 있다며 최대 1억원에 달하는 영성상품을 판매하고 신도들을 강제로 추행한...  \n",
       "...                                                 ...  \n",
       "3814  한샘, 현대리바트 등 13개 가구업체가 반도건설이 발주한 아파트 특판가구 입찰에서 ...  \n",
       "3815  수천억원대 분식회계와 채용 비리 의혹 등으로 재판에 넘겨진 하성용 전 한국항공우주산...  \n",
       "3816  대한민국이 좀처럼 혼돈에서 벗어나지 못하고 있다. 헌법재판소의 윤석열 대통령 탄핵 ...  \n",
       "3817  찍힌 기관들 사실상 폐쇄 절차 사법부 ‘일시 중단’ 명령도 무시\\n\\n\\n\\n[주간...  \n",
       "3818  아시아투데이 전원준 기자 = 서울 강남 3구(강남 서초 송파구) '국민평형' 아파트...  \n",
       "\n",
       "[3819 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['제목', '본문']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effb3357",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2040e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서: 개별 뉴스기사 (제목 + 본문)\n",
    "# 전처리 + 토큰화 - 소문자 통일, 형태소 단위 토큰화\n",
    "\n",
    "# gensim을 이용해서 embedding 모델 학습\n",
    "\n",
    "# 결과 확인 -> 유사도 검사사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7524d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
