{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81228c24-0333-4690-a40a-4110e0c0f6b4",
   "metadata": {},
   "source": [
    "# Contextualized Word Embedding\n",
    "- Word Embedding처럼 단어를 저차원 벡터 공간에 표현하되, **각 단어가 문맥 내에서 가지는 의미를 반영하는** 문맥 기반 단어 표현 방식이다.\n",
    "  \n",
    "## Word Embedding과의 차이\n",
    "\n",
    "- 기존 Word Embedding 방식은 **동음이의어**(같은 발음에 여러 뜻을 가진 단어)가 **같은 벡터**로 표현되기 때문에, 문장의 의미(내용)이  제대로 표현되지 못할 수 있다.  \n",
    "    - 예: \"밤에 만나자.\"와 \"어제 먹은 밤 정말 맛있었다.\"라는 두 문장에서 '밤'은 서로 다른 의미이지만, word2vec과 같은 Word Embedding 방식에서는 동일한 벡터로 표현된다.\n",
    "- **Contextualized Word Embedding**은 동일한 발음의 단어라도 **문맥에 따라 각기 다른 벡터를 생성하여** 단어의 의미를 정확히 표현하는 것을 목표로 한다.  \n",
    "    - 예: Contextualized Word Embedding은 **동의 이의어의 단어라도 그 문장에서 어떤 의미로 사용되는지에 맞게 다르게 벡터화**한다. 따라서 위의 예의 두 문장에서 사용된 '밤'은 서로 다른 벡터로 표현된다.\n",
    " \n",
    "## Contextualized Word Embedding 구현 방식\n",
    "- 딥러닝 모델로 구현한다.\n",
    "    - Word2vec이 하나의 hidden layer로 구성되는 것과는 달리, 많은 layer들을 연결해서 deep한 네트워크 모델로 정의한다.\n",
    "- Contextualized Word Representation은 문장을 입력 받아 그 문장 내의 각 단어에 대한 표현을 추정한다.\n",
    "    - **🌟문장을 구성하는 단어들을 기존 word embedding 벡터값 입력받은 뒤, neural network의 layer들을 거치면서 문장(문맥)내에서 어떤 의미로 사용되었는지를 표현하는 vector를 생성한다.**\n",
    "- 예전에는 RNN계열의 딥러닝 모델들을 사용했으나,  최근에는 [Attention Is All You Need](https://arxiv.org/pdf/1706.03762) 논문에서 제안한 Transformer 계열의 모델을 주로 사용한다.\n",
    "- **대표적 모델**\n",
    "    - ELMo (Embeddings from Language Models)\n",
    "    - BERT (Bidirectional Encoder Representations from Transformers)\n",
    "    - GPT (Generative Pre-trained Transformer)\n",
    "    - RoBERTa (A Robustly Optimized BERT Pretraining Approach)\n",
    "- 대부분 대규모 Dataset에서 사전 학습(pre-training)모델을 자신의 작업에 맞춰 미세 조정(fine-tuning)하여 사용한다.\n",
    "\n",
    "> - **동음이의어**\n",
    ">     - 같은 발음은 같은데 뜻이 다른 단어를 **동음이의어** 라고 한다.\n",
    ">     - 예로 먹는 \"밤\" 과 해가 떨어진 시간대를 나타내는 \"밤\", 먹는 \"배\"와 타는 \"배\"와 사람의 \"배\"\n",
    "> - **동음다의어**\n",
    ">     - 하나의 단어가 여러개의 관련된 뜻을 가진 것을 **동음다의어**라고 한다.\n",
    ">     - 예) \"머리를 끄덕이다.\", \"머리가 좋다.\" , \"머리가 길다\"  셋다 관련되 있지만 다른 뜻으로 쓰인다.\n",
    ">         - [네이버사전 머리뜻](https://ko.dict.naver.com/#/entry/koko/a90afd48126045a09bc9b6c634b7ff54)을 보면 머리에서 파생된 의미가 11가지가 나와 있다. (중심의미로 부터 파생된 파생의미들.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c368d7e2",
   "metadata": {},
   "source": [
    "기존에 학습한 모델을 바탕으로 + 문맥을 학습 데이터에 맞게 다시 학습하겠다!!\n",
    "\n",
    "기존에 학습한 모델을 그대로 쓰지만은 않겠다~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b0375",
   "metadata": {},
   "source": [
    "문맥을 학습? -> RNN, Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc7778c-0d43-4d4a-a495-ecf78a8cdd27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43a60c40-ad77-40c4-a89a-0215dfb0e30f",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network (RNN)\n",
    "\n",
    "- Sequential data 의 특성을 추출하는데 좋은 성능을 보이는 Recurrent Layer를 Feature Extractor로 사용하는 딥러닝 모델.\n",
    "- 시계열 데이터, 자연어처리, 음성데이터 처리에 많이 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28078254-f3d9-4917-868a-6c9e684f385f",
   "metadata": {},
   "source": [
    "# Sequential 데이터란\n",
    "\n",
    "- 데이터의 **순서가 있고 그 순서 정보가 중요한 데이터셋**\n",
    "    - 순서가 달라질 경우 의미가 바뀌거나 손상되는 데이터.\n",
    "    - 처리시 **순서의 흐름이(Context:문맥) 중요한 데이터**\n",
    "        - 현재 순서의 값을 처리할 때 이전 순서까지의 처리 결과들을 모두 같이 고려해야 하는 경우.\n",
    "- 예\n",
    "    - 자연어 텍스트\n",
    "    - 일정한 주기로 샘플링된 영상, 음성\n",
    "    - 시계열(time series) 데이터\n",
    "> - Time series\n",
    ">    - Sequential 데이터 중 데이터의 순서에 뿐 아니라 해당 **데이터가 발생한 시점 정보가 중요한 데이터셋을** 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef67f648-4c58-4f51-af08-785ce7e85937",
   "metadata": {},
   "source": [
    "# RNN (Recurrent Neural Network) 구조\n",
    "\n",
    "## 개요\n",
    "- RNN은 Feature Extractor로 Recurrent Layer을 사용하는 딥러닝 모델(네트워크)을 말한다.\n",
    "- Recurrent Layer는 sequential 데이터 처리에 좋은 성능을 낸다.\n",
    "\n",
    "![rnn_outline](figures/rnn/RNN_outline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d327e83f",
   "metadata": {},
   "source": [
    "RNN 돌릴 때 W(weight)는 \"하나\"이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b668b1cf",
   "metadata": {},
   "source": [
    "h1: '이'\n",
    "\n",
    "h2: '이 영화'\n",
    "\n",
    "h3: '이 영화 정말'\n",
    "\n",
    "h4: '이 영화 정말 재미있다'\n",
    "\n",
    "=> h4를 feature 분류기에 넣어준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e30211-1b9b-42cb-9625-1fbb789fc6aa",
   "metadata": {},
   "source": [
    "## Recurrent Layer 구조\n",
    "- Sequential 데이터는 순서에 맞춰 처리하는 것이 중요하다. 그러나 DNN과, CNN에서 사용되는 Fully Connected Layer나 Convolutional Layer는 순서를 고려하지 않고 특성 추출 한다.\n",
    "- RNN은 순서대 입력되는 데이터를 반복 처리하는  **Recurrent Layer**를 이용해 **순서를 가만해서 Feature vector를 추출하고** 그 Feature vector를 Estimator Layer에 전달해 추론한다.\n",
    "- **순서를 가만한다는 것**은 이전 순서의 내용을 기억한다는 것을 말한다. 이것을 memory system이라고 한다.\n",
    "\n",
    "### 메모리 시스템(Memory system)\n",
    "- **이전 시점까지의 특성들을 이용해 현재 시점의 특성을 추출한다.**\n",
    "    - Sequential Data는 단순히 순서대로 처리하는 것 뿐 만 그 내용들을 **⭐기억(memory)⭐** 하고 **참고** 해서 현재 순서의 내용을 처리해야 한다.\n",
    "    - 메모리 시스템이란 **\"이전 단계의 처리결과를 기억하고 그것을 현재 단계 처리에 사용하는\"** 것으로 Recurrent layer의 핵심 로직이다.\n",
    "\n",
    "> Sequential 데이터 처리에서 순서대로 처리할 때 각각의 단계(순서)를 **time step** 이라고 한다.\n",
    " \n",
    "![memory system](figures/rnn/01_memory_system.png)\n",
    "\n",
    "- 예를 들어 4일간의 주가 변화로 5일째 주가를 예측하려면 입력받은 4일간의 주가 정보를 순서대로 기억하고 있어야 한다.\n",
    "- Fully Connected Layer나 Convolution Layer의 출력은 이전 Data에 대한 처리와 상관없이 현재 시점의 데이터만을 기준으로 특성(feature)을 추출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2a4b01-660e-46b7-85ff-ea513a4e3bb4",
   "metadata": {},
   "source": [
    "### Simple RNN 구조\n",
    "![rnn arch](figures/rnn/02_simplernn.png)\n",
    "\n",
    "\n",
    "![rnn_arch2](figures/rnn/03_simplernn_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51915de",
   "metadata": {},
   "source": [
    "- 우리가 찾으려는 건 \"문장의 특성\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fefa278-785b-4dcb-aaa7-622a6be6c162",
   "metadata": {},
   "source": [
    "- Recurrent Layer는 Linear layer 구조에 **재귀 순환(반복)의 로직**이 들어간 것으로 이해할 수 있다.\n",
    "- Layer의 한 step은 입력으로 **현재 시점(time step)의 입력 데이터($X_{t}$)** 와 **이전 시점까지의 처리결과($h_{t-1}$)** 를 같이 받는다.  (t: time step)\n",
    "- $X_{t}$와 $h_{t-1}$ 에 각각의 weight($W_{xh}\\,, W_{hh}$)를 이용해 가중합을 구하고 그 둘의 합계를 activation(tanh) 함수에 넣어 비선형성을 추가한 결과가 현재 time step의 출력값이된다. **이 출력값이 현재 time step의 feature(특성)값** 이다.\n",
    "    - 이 출력값은 현재 time step의 feature 이자 **다음 time step의 feature 계산의 hidden state 입력값으로 사용된다.**\n",
    "    - $X_{t}$(현재 time step의 입력)와 $h_{t-1}$(hidden state) 에는 각각 다른 weight($W_{xh}$ , $W_{hh}$)들이 적용된다.\n",
    "- 매 time step마다 동일한 weight $W_{xh}$와 $W_{hh}$ 가 사용된다.\n",
    "    - time step 마다 새로운 weight들이 적용되는 것이 아니다.\n",
    "\n",
    "> #### Hidden state\n",
    "> - 이전 step까지의 처리결과를 말한다..\n",
    "> - **메모리 시스템의 메모리(기억)** 에 해당한다.\n",
    "> - 현재 timestep의 feature를 추출할 때 현재 시점의 입력과 함께 recurrent layer의 입력으로 들어간다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe180f6-3fe2-4b25-b629-c4f55ad4113e",
   "metadata": {},
   "source": [
    "## NLP 문제 유형과 RNN 구조\n",
    "\n",
    "|유형|구조1|구조2|구현서비스(App)|\n",
    "|:-|:-|:-:|:-|\n",
    "|**Many to One**|입력: Sequence Vector(여러개의 Vector)<br>출력: 1개 Vector|![mto](figures/rnn/04_many_to_one.png)|$\\scriptscriptstyle\\blacksquare$ Text classification(감성 분석)|\n",
    "|**One to Many**|입력: 1개 Vector<br>출력: Sequence Vector|![otm](figures/rnn/04_one_to_many.png)|$\\scriptscriptstyle\\blacksquare$ Image captioning<br>$\\scriptscriptstyle\\blacksquare$ 문장생성|\n",
    "|**Many to Many**|입력: Sequence Vector<br>출력: Sequence Vector|![mtm1](figures/rnn/04_many_to_many.png)|$\\scriptscriptstyle\\blacksquare$ 개체명인식<br>$\\scriptscriptstyle\\blacksquare$ 품사태깅|\n",
    "|**Seq2Seq**|many to one과 one to many 를 연결한 구조.<br>Encoder, Decoder 구조<br>Encoder는 **특성을 추출**하고 <br>Decoder는 Encoder가 추출한 특성을 이용해 **결과를 생성.**|![seq2seq](figures/rnn/04_seq2seq.png)|$\\scriptscriptstyle\\blacksquare$ Machine Translation<br>$\\scriptscriptstyle\\blacksquare$ Chatbot|\n",
    "\n",
    "\n",
    "- **텍스트 분류(Text classification)**\n",
    "   - 입력받은 문장을 분류하는 문제로 대표적으로 감성분석(sementic analysis)가 있다.\n",
    "   - 감성분석\n",
    "       -  입력받은 텍스트가 어떤 감정의 글인지를 분류한다. 일반적으로 긍정, 중립, 부정적 인지를 분류한다.\n",
    "- **Image captioning**\n",
    "   - 입력받은 이미지를 설명하는 문장을 생성하는 문제.\n",
    "- **개체명인식(Named Entity Recognition)**\n",
    "   - 문장의 각 단어가 어떤 종류(의미) 인지를 찾는 문제\n",
    "   - 미국에 사는 톰은 스무살입니다. ==> 미국: 위치, 톰: 이름, 스므살: 나이\n",
    "- **품사태깅(Pos tagging)**\n",
    "   - 문장의 각 토큰의 품사를 찾는 문제\n",
    "   - 미국에 사는 톰은 스무살입니다. ==> 미국: 대명사, 예: 조사,  톰: 대명사, 은: 조사, 스무: 명사, 살: 명사, 이다: 동사\n",
    "- **Chatbot** ✅\n",
    "   - 입력받은 문장에 대한 답을 하는 시스템.\n",
    "   - Encoder는 질문을 받아 처리하고 Decoder는 답변을 생성하는 seq2seq 구조를 사용한다.\n",
    "- **Machine translation**\n",
    "   - 번역 시스템\n",
    "   - Encoder는 번역 대상문장을 입력받아 처리하고 Decoder는 번역 문장을 생성하는 seq2seq 구조를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc32fd34",
   "metadata": {},
   "source": [
    "Many to One 그림에서 초록이 3개인데 -> 레이어가 3개인가요? (X) 레이어는 1개!!🌟    \n",
    "똑같은 레이어에 입력 데이터를 세 개 넣는 거예요. 그래서 가중치가 똑같은 거고, 최종적으로 맨 마지막 hidden layer인 h3(그림상으로)만 쓰겠다는 거죠!!\n",
    "\n",
    "One to Many   \n",
    "'나는'을 Feature Extractor를 넣으면 -> 다음 단어를 예측하게 한다. y를 출력하는 hidden layer로 분류 모델을 학습해서, '나는' 다음에 나올 단어가 뭔지 예측하게 하는 거다. '나는' -> '어제' 이런 식으로.   \n",
    "이때 X1 처리 결과 h1, y1 -> h1과 y1 을 다음 입력으로 넣는다.   \n",
    "x1: '나는' 입력 -> h1: x1의 특징 추출, y1: '어제' -> x2: '어제'(=y1) 입력 -> ...   \n",
    "=>  모델 레이어에는 생성된 값을 알아서 넣는 거고, 실제 사용자가 모델에 입력한 값은 x1 '나는' 하나 뿐이라는 의미에서 One to Many인 것임. 모델 레이어에는 계속 입력값이 들어간다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066ae1fb",
   "metadata": {},
   "source": [
    "#### seq2seq\n",
    "- 입력과 출력 둘 다 특성을 추출해야 함. 챗봇, 번역 등에 사용된다. \n",
    "- LSTM, GRU를 쓸 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371a3eab",
   "metadata": {},
   "source": [
    "이 구조에는 이걸 무조건 써야 한다 (X)   \n",
    "구조와 모델을 적절히 선택해 쓰자 (O)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c212f68d-b27c-4725-901c-7e98a422ef8d",
   "metadata": {},
   "source": [
    "## Recurrent Layer 구조들\n",
    "\n",
    "### Bidirectional RNN\n",
    "- 같은 정보를 정방향과 역방향 두 방향으로 주입해 정확도를 높인다.\n",
    "- Non-Auto Regressive 모델의 경우 bidirectional RNN 사용이 권장된다.\n",
    "\n",
    "> - **Auto Regressive 모델** \n",
    ">     - **이전 time step에 대한 출력결과를 다음 time step의 입력으로 사용**하는 구조.\n",
    ">         - **Text 생성 모델**이 대표적인 Auto Regressive 모델이다.\n",
    ">     - **이전 출력의 결과에 의존하기 때문에 bidirectional RNN을 사용할 수 없다.**\n",
    ">     - Non Auto Regressive 모델은 현재의 상태가 앞/뒤 상태에 따라 정해지는 경우로 보통 앞/뒤의 상태를 모두 참조할 경우 성능이 올라간다. 그래서 단방향 RNN보다 bidirectional RNN의 사용이 권장된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9a16bb-d113-4d08-814a-6065b57f96c2",
   "metadata": {},
   "source": [
    "![bidirectional](figures/rnn/08_bidirectional.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb53f18-66db-474d-acdf-2963c6837916",
   "metadata": {},
   "source": [
    "### Stacking(Multi Layer) RNN\n",
    "\n",
    "- Recurrent Layer를 쌓아 모델의 용량을 늘려 표현능력(Represenational capacity)를 증가시킨다.\n",
    "- 여러층을 쌓은 경우 먼저 쌓은 layer의 모든 time step별 출력이 다음 Layer의 입력 데이터로 사용된다.\n",
    "- Layer을 쌓으면 표현능력은 증가하는 대신 계산 비용이 많이들고 **과대적합(Overfitting)이** 발생할 수 있다.\n",
    "    - 과대적합을 막기 위해 드롭아웃 레이어를 추가할 수있다.\n",
    "    - Recurrent Layer에서 Dropout layer는 매 time step 마다 적용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cbc98e-5794-41d4-9f86-4339790557fd",
   "metadata": {},
   "source": [
    "![stacking rnn](figures/rnn/08_multi_layer_rnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aeefa1-2cdf-4535-9227-c7a125fd8883",
   "metadata": {},
   "source": [
    "## Pytorch RNN Layer\n",
    "\n",
    "- [nn.RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html)\n",
    "    - **파라미터**\n",
    "        - input_size: 입력 데이터의 크기 (feature수)\n",
    "        - hidden_size: Layer의 Hidden size = hidden layer에서 몇 개의 feature를  추출할 것인지\n",
    "        - num_layers: 몇 층으로 Layer을 쌓을지 개수\n",
    "        - nonlinearity: 활성함수(Activation Function) 지정. 문자열로 'tanh' (Default) 또는 'relu' 둘 중 하나 지정.\n",
    "        - batch_first: True - (batch, seqence len, ..) False - (sequence len, batch, ..). Default: False\n",
    "        - dropout: Dropout rate 비율\n",
    "        - bidirectional:  양방향 적용 여부. Default: False\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194402cf",
   "metadata": {},
   "source": [
    "`batch_first = True`\n",
    "\n",
    "batch size=200이라 했을 때, True: (200, 1, 28, 28)과 같이 (b, c, h, w)로 넣을 건지, \n",
    "\n",
    "아니면 False: batch size와 channel의 순서를 바꿔서 (1, 200, 28, 28)로 입력을 받을 건지\n",
    "\n",
    "이렇게 되면 모델이 0번 축에서 배치 사이즈를 읽을 건지, 아니면 채널을 먼저 읽을건지(False: default)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d966f316-99c6-408d-8b34-63f83eefbf61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "  \n",
    "### RNN Layer의 input / output tensor 의 shape\n",
    "\n",
    "### 추론시 Input\n",
    "- 입력으로 두개를 받는다.\n",
    "    - Input_Data, Hidden_state\n",
    "- **Input_data의 shape**\n",
    "    - (Sequence_legnth, batch_size, feature_shape)\n",
    "        - pytorch는 입력으로 batch보다 sequence length가 먼저 온다.\n",
    "        - `batch_first=True`로 설정하면 (**batch_size**, seq_len, feature_shape) 순이 된다.\n",
    "        - ex)  주가 데이터\n",
    "            - feature: 시가, 종가, 최고가, 최저가 (4개)\n",
    "            - sequence: 100일치( 100개의 feature가 하나의 입력이 된다.)\n",
    "            - batch size: 30 (100일치 데이터 30개)\n",
    "            - (100, 30, 4)\n",
    "    ![input tensor shape](figures/rnn/07_input_shape.png)\n",
    "- **Hidden state의 shape**\n",
    "    - 시작(초기) hidden state로 입력하지 않으면 0이 들어간다.\n",
    "    - shape은 아래 hidden state 설명 참조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d6c638",
   "metadata": {},
   "source": [
    "문장 데이터를 예로 들자면:\n",
    "\n",
    "- batch_size = 10: 10개의 문장\n",
    "- sequence = 4: 하나의 문장은 4개의 임베딩 벡터로 구성되어 있다.\n",
    "- feature = 3: 임베딩 벡터는 3차원이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e04175c-65d5-43dd-b3dc-5646d390b47a",
   "metadata": {},
   "source": [
    "### 🌟Output\n",
    "- **(output_data, hidden_state)**\n",
    "    - output_data과 hidden state를 tuple로 묶어서 반환한다.\n",
    "- 🌟**Output_data**:\n",
    "    - **매 time step의 출력결과**\n",
    "    - Many to Many일 경우 이것을 출력 Feature들로 사용한다.\n",
    "- 🌟**hidden_state**\n",
    "    - **\"마지막\" time step의 출력결과**\n",
    "    - Many to one의 경우 이것을 출력 Feature로 사용한다.\n",
    "  \n",
    "#### Output shape\n",
    "- **(Sequence length, batch_size, hidden_size * D)**\n",
    "    - D: 양방향(bidirectional) 이면 2 아니면 1\n",
    "    - batch_first=True 로 설정하면 (**batch_size**, seq_len, hidden_size * D) 순이 된다.\n",
    "    - ex)\n",
    "        - RNN Layer의 hidden size가 256 인 경우. (sequence length: 100, batch size: 30, bidirection=False)\n",
    "        -  (100, 30, 256)\n",
    "![hidden state shape](figures/rnn/07_hidden_state_shape.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e97aff-48db-4083-b6fb-10651ac518ba",
   "metadata": {},
   "source": [
    "#### Hidden state\n",
    "- 마지막 time step의 출력결과\n",
    "    - **(D * layer수, batch_size, hidden_size)**\n",
    "    -  D: 양방향(bidirectional) 이면 2 아니면 1\n",
    "    -  layer수: multi layer일 경우 layer stack 수\n",
    "        -  각 Layer 별 마지막 time step의 결과들이 묶여서 hidden state 가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3987f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c1010f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 - 3차원, batch_first = False: \n",
    "# (seq_length: data를 구성하는 timestep의 개수 => 개별 문서의 단어 수\n",
    "# batch_size: 입력 데이터 개수 => 한 번에 입력되는 문서의 개수\n",
    "# feature): 각 timestep을 구성하는 feature의 개수 => 단어의 임베딩 차원 수\n",
    "\n",
    "input_data = torch.randn((30, 100, 4)) # batch_first=False => (seq_len, batch_size, feature)\n",
    "# 개별 단어(데이터): 4개 값을 구성\n",
    "# 한 개 문장(문서, 입력데이터): 30개 단어로 구성\n",
    "# 학습하거나 추론할 때 총 100개 문장을 쓰겠다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f14894",
   "metadata": {},
   "source": [
    "### 🍒 아래 input data는! \n",
    "1. 토큰화를 해 문장을 쪼개고\n",
    "2. 임베딩 벡터로 변환한 것임\n",
    "3. 이 input data를 RNN 모델에 넣는 거임~!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32d82ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8197,  0.4098,  0.3472,  0.7944],\n",
       "         [-0.4212,  2.3283, -2.1874,  0.2150],\n",
       "         [-0.9724, -0.5959,  0.6254, -2.1679],\n",
       "         ...,\n",
       "         [ 0.2281, -0.7096, -1.3660, -0.4903],\n",
       "         [ 0.1822,  0.3534,  0.6868, -0.5137],\n",
       "         [ 1.0185,  0.3497, -0.0589, -0.4458]],\n",
       "\n",
       "        [[ 0.0696,  0.6168, -2.0375, -0.2419],\n",
       "         [ 0.5339,  0.0658,  1.7463, -0.9939],\n",
       "         [-0.3090, -0.4292,  0.2857, -0.9900],\n",
       "         ...,\n",
       "         [-0.9566,  0.2864, -1.4170,  0.7634],\n",
       "         [ 0.2267, -0.2551,  0.2383,  0.6169],\n",
       "         [ 0.8773,  1.0174,  0.8420,  0.1331]],\n",
       "\n",
       "        [[-0.9082, -0.0172,  0.0225, -1.0232],\n",
       "         [ 0.7637, -1.7480, -0.7871, -0.5890],\n",
       "         [-0.7751, -1.2217, -0.0689, -0.0638],\n",
       "         ...,\n",
       "         [-0.9610, -0.0862, -1.4762, -0.6155],\n",
       "         [ 1.9784,  0.9721, -0.1417,  0.5961],\n",
       "         [-1.4194,  0.4470,  1.1145, -0.1480]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1000,  0.0168, -1.5208, -2.2709],\n",
       "         [-1.1370,  0.1267,  0.5208, -0.7841],\n",
       "         [ 1.7945, -0.6579, -0.0492,  0.2535],\n",
       "         ...,\n",
       "         [-0.5373,  0.9979,  0.8577,  0.3987],\n",
       "         [ 0.0847, -0.5044,  1.6218, -1.8068],\n",
       "         [-1.1700,  0.0725,  0.6066,  1.3231]],\n",
       "\n",
       "        [[-0.2134, -1.3843,  0.7416,  0.1947],\n",
       "         [-0.4640,  0.6007, -0.8515, -0.3982],\n",
       "         [-0.7490, -0.5147,  1.1816,  1.7679],\n",
       "         ...,\n",
       "         [ 0.8193,  0.1940, -1.3634, -1.1044],\n",
       "         [ 0.2891,  0.2992,  1.5273, -1.1207],\n",
       "         [-1.3474, -1.2280,  0.9116,  1.0202]],\n",
       "\n",
       "        [[-0.8019, -0.8668, -0.0098, -0.0551],\n",
       "         [ 0.1022,  0.8194,  0.4433, -0.1837],\n",
       "         [ 0.1797,  0.4842,  1.0446,  0.4837],\n",
       "         ...,\n",
       "         [ 0.9128,  0.7874, -0.5655,  0.4329],\n",
       "         [-0.9972,  0.4405, -1.1485, -1.0096],\n",
       "         [ 1.9042, -0.1816, -0.4485,  0.3707]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eba29a",
   "metadata": {},
   "source": [
    "layer 수: 1, 단방향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7e839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "torch.Size([30, 100, 256])\n",
      "torch.Size([1, 100, 256])\n"
     ]
    }
   ],
   "source": [
    "rnn1 = nn.RNN(\n",
    "    input_size=4,           # 개별 timestep의 feature 수\n",
    "    hidden_size=256,        # 개별 timestep별로 추출할 feature의 개수. Unit/Node의 개수 (하이퍼파라미터)\n",
    "    num_layers=1,           # multi layer RNN -> 쌓을 layer의 개수\n",
    "    # batch_first=True      # (batch, seq_length, feature)\n",
    "    # nonlinearity=\"relu\"   # 활성함수. default: \"tanh\"\n",
    ") # 하나의 layer를 만든 것임!\n",
    "\n",
    "output = rnn1(input_data)   # (30: seq_length, 100: batch, 4: feature)\n",
    "print(type(output))         # (output_data: 모든 timestep의 hiddenstate, hidden: 마지막 timestep의 hiddenstate)\n",
    "\n",
    "out1, hidden1 = rnn1(input_data)\n",
    "print(out1.shape) # tensor\n",
    "print(hidden1.shape) # tensor\n",
    "\n",
    "# [30: seq_len, 100: batch, 256: hidden_size] # 모든 timestep의 결과\n",
    "# [1: seq_len, 100: batch, 256: hidden_size] # 마지막 timestep의 결과\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab24c3c",
   "metadata": {},
   "source": [
    "`hidden_size=256`: 단어의 특징을 추출할 때 RNN 레이어 결과로 256개, hidden state도 256개를 뽑는 거다. => 파라미터도, weight도 256개가 되어야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc8dde",
   "metadata": {},
   "source": [
    "layer 수: 1, 양방향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96749be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 100, 512])\n",
      "torch.Size([2, 100, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0151,  0.0275,  0.1520,  ..., -0.0939,  0.1048, -0.0016],\n",
       "         [-0.0192, -0.0253, -0.0516,  ..., -0.0430, -0.0158,  0.0340],\n",
       "         [ 0.2854, -0.1229, -0.0590,  ..., -0.1595, -0.0845, -0.0992],\n",
       "         ...,\n",
       "         [ 0.2227, -0.0615, -0.0177,  ..., -0.0130,  0.0053,  0.0570],\n",
       "         [-0.1104, -0.0401,  0.0184,  ...,  0.0350, -0.0333,  0.1202],\n",
       "         [-0.0004, -0.0761, -0.1379,  ..., -0.0292, -0.0227, -0.0637]],\n",
       "        grad_fn=<SelectBackward0>),\n",
       " tensor([[-0.2302,  0.0022, -0.1195,  ...,  0.0560,  0.0646, -0.0385],\n",
       "         [-0.2011, -0.0175, -0.0547,  ...,  0.0465, -0.0514,  0.0527],\n",
       "         [-0.2444,  0.0255, -0.1080,  ...,  0.0406,  0.1058, -0.0325],\n",
       "         ...,\n",
       "         [-0.2470, -0.1855, -0.0250,  ..., -0.1021, -0.1133,  0.0499],\n",
       "         [-0.1490, -0.1989, -0.0965,  ..., -0.0811, -0.0205, -0.1596],\n",
       "         [-0.2106, -0.0172,  0.0153,  ..., -0.1573, -0.0526, -0.0293]],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn2 = nn.RNN(\n",
    "    input_size=4,           # 개별 timestep의 feature 수\n",
    "    hidden_size=256,        # 개별 timestep별로 추출할 feature의 개수. Unit/Node의 개수 (하이퍼파라미터)\n",
    "    num_layers=1,           # multi layer RNN -> 쌓을 layer의 개수\n",
    "    bidirectional=True      # 양방향 RNN 여부 (default: False)\n",
    ")\n",
    "\n",
    "out2, hidden2 = rnn2(input_data)\n",
    "print(out2.shape) \n",
    "print(hidden2.shape)\n",
    "\n",
    "# [30, 100, 512: 순/역방향 결과를 concat]\n",
    "# [2: 순/역방향, 100, 256]\n",
    "\n",
    "hidden2[0], hidden2[1] # 순방향, 역방향 -> 합쳐져 있는 게 hidden2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba4c4d",
   "metadata": {},
   "source": [
    "layer 수: 3, 단방향 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628216a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 100, 256])\n",
      "torch.Size([3, 100, 256])\n"
     ]
    }
   ],
   "source": [
    "rnn3 = nn.RNN(\n",
    "    input_size=4,           # 개별 timestep의 feature 수\n",
    "    hidden_size=256,        # 개별 timestep별로 추출할 feature의 개수. Unit/Node의 개수 (하이퍼파라미터)\n",
    "    num_layers=3            # multi layer RNN -> 쌓을 layer의 개수\n",
    ")\n",
    "out3, hidden3 = rnn3(input_data)\n",
    "print(out3.shape) # [30, 100, 256] -> 모든 timestep의 (마지막 layer가 출력한) hidden state들.\n",
    "print(hidden3.shape) # [3: 레이어 수, 100, 256] -> 레이어별 마지막 timestep의 hidden state들을 모아서 반환."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300e7923",
   "metadata": {},
   "source": [
    "layer 수: 3, 양방향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02616da3-d879-4a11-b63e-804ede8241b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 100, 512])\n",
      "torch.Size([6, 100, 256])\n"
     ]
    }
   ],
   "source": [
    "rnn4 = nn.RNN(\n",
    "    input_size=4,           # 개별 timestep의 feature 수\n",
    "    hidden_size=256,        # 개별 timestep별로 추출할 feature의 개수. Unit/Node의 개수 (하이퍼파라미터)\n",
    "    num_layers=3,           # multi layer RNN -> 쌓을 layer의 개수\n",
    "    bidirectional=True      # 양방향\n",
    ")\n",
    "\n",
    "out4, hidden4 = rnn4(input_data)\n",
    "print(out4.shape) # [30, 100, 512: 순/역방향향]\n",
    "print(hidden4.shape) # [6: 레이어수(3) x 양방향(2), 100, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a74f2a5-d789-439e-a0d7-fd73c3175c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cd9f640-e5cb-4439-9e34-40d7cb702a3f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fe880b3-a1ca-4158-ad64-0856b90bea78",
   "metadata": {},
   "source": [
    "# RNN의 Back Propagation \n",
    "- **BPTT(Back Propagation Through Time)** 이라고 한다.\n",
    "- RNN time step 별로 순환 반복는 hidden state의 흐름의 역방향으로 전파되는 gradient 들이 chain rule에 의해 곱해지면서 weight가 업데이트 된다.\n",
    "    - 각 time step 마다 사용되는 weight는 같기 때문에 1 step에서 weight는 여러번(time step수만큼)에 걸쳐 업데이트 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f75381-a29a-4e97-93ff-0bea964a798f",
   "metadata": {},
   "source": [
    "## RNN(Simple RNN)의 문제 \n",
    "- 입력 데이터의 sequence가 길수록 Gradient Vanishing이 발생해 초기 Sequence에 대한 학습이 안되는 문제가 RNN의 고질적인 문제이다.\n",
    "    - RNN은 activation 함수로 tanh()를 사용한다. tanh()의 gradient는 0 ~ 1 사이의 실수가 나온다. 그래서 sequence가 길어지면 **초기 time step의 값에 대한 weight가 업데이트가 되지 않게** 된다.  \n",
    "- Time step이 길어지면 초기 Sequence에 정보가 hidden state에서 점점 사라지는 **기억력 소실문제**가 발생한다.\n",
    "      \n",
    "![BPTT](figures/rnn/09_bptt.png)\n",
    "\n",
    "- 이런 Simple RNN의 문제 모델 구조로 해결한 모델이 **LSTM이나 GRU** 모델이다. Sequence 데이터 처리 모델로 이 둘을 주로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3a20f4",
   "metadata": {},
   "source": [
    "## 요약\n",
    "RNN은 기억력 소실 문제(vanishing grad)가 발생. 왜? 구조적으로    \n",
    "-> 구조를 바꿔줍시다. -> LSTM, GRU: RNN 컨셉을 가져오되, 계산 방법 변형한 것.    \n",
    "이들은 주로 RNN 계열 모델이라고 칭함\n",
    "\n",
    "GRU: LSTM Gate 개념을 가져오되, 연산량을 줄인 것 => LSTM보다 성능이 더 좋아진 것은 아님.   \n",
    "=> LSTM이 오랫동안 쓰였음.\n",
    "\n",
    "RNN에서 LSTM 이후로 성능을 더 좋게 만드는, Attention을 활용해 새로운 구조로 나온 게 Transformer이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2ca22-3cea-4d5f-b9b1-33fb14998d43",
   "metadata": {},
   "source": [
    "# LSTM (Long Short Term Memory: 장기 단기 기억 시스템)\n",
    "\n",
    "## 개요\n",
    "- Simple RNN을 개선한 변형 알고리즘\n",
    "    - 🌟**오래 기억할 것은 유지하고 잊어버릴 것은 빨리 잊어버리자**\n",
    "    - 바로 전 time step의 처리 결과와 전체 time step의 처리 결과를 같이 받는다.\n",
    "\n",
    "\n",
    "![lstm](figures/rnn/09_lstm_layer.png)\n",
    "\n",
    "- Simple RNN과 다르게 두개의 이전 time step까지의 처리결과를 사용한다.\n",
    "    - **Cell State**\n",
    "        - Long term memory 로 **전체 step에 대한 누적 기억값**\n",
    "    - **Hidden State**\n",
    "        - Short term memory 로 **이전 sequence 에 대한 기억값**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a87ce-dd27-42ec-90f6-80d64b20f686",
   "metadata": {},
   "source": [
    "## LSTM  Gate: 값을 얼마나 사용할지에 대한 Gate\n",
    "0과 1 사이 비율을 생성해서 값을 얼마나 사용할지를 지정한다.   \n",
    "- 0: 값을 안 쓰겠다, 1: 값을 그대로 쓰겠다, 보통은 이 사이 값으로~ \n",
    "\n",
    "\n",
    "- Gate\n",
    "    - LSTM은 Layer내에 여러개의 **Gate 연산** 통해 성능을 높인다.\n",
    "    - Sigmoid연산을 이용해 값의 얼마를 적용할지 정한다. 이것을 문이 열리고 닫히는 의미로 Gate라고 한다.\n",
    "- LSTM은 3개 Gate를 사용한다.\n",
    "    -  **Forget gate**: 얼마나 잊어버릴지에 대한 비율을 만든다\n",
    "    -  **Input gate**: 얼마나 입력 받을지(사용할지)\n",
    "    -  **Output gate**: 얼마나 출력할지(내보낼지)\n",
    "-  각 Gate는 hidden state와 Input data에 곱하는 Weight들을 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7827d9d-bc6f-4e8e-ae6f-79f9f83ceaa0",
   "metadata": {},
   "source": [
    "![lstm](figures/rnn/10_lstm_layer_all.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa52849-2742-48a8-91ba-b73ecf2d1a3b",
   "metadata": {},
   "source": [
    "### Forget gate\n",
    "![forget gate](figures/rnn/11_forget_gate.jpg)\n",
    "\n",
    "- 이전 time step의 hidden state와 현재 time step의 입력데이터를 기준으로 장기 기억인 cell state에서 얼마나 잊을 지 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511772d5-da37-4504-adde-143906285e20",
   "metadata": {},
   "source": [
    "### Input Gate\n",
    "\n",
    "![input gate](figures/rnn/12_input_gate.jpg)\n",
    "- 이전 time step의 hidden state와 현재 time step의 입력데이터를 cell state에서 얼마나 반영할 지 계산한다.\n",
    "- \"장기기억에 얼마나 추가할지\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a69ac70-0a6e-4926-8971-9297f8ceab9b",
   "metadata": {},
   "source": [
    "### Cell State update\n",
    "\n",
    "![update](figures/rnn/13_cell_state_update.jpg)\n",
    "- cell state는 forget gate의 결과를 곱해서 얼마나 잊을지 결정하고 input gate의 결과를 더해서 현재 입력에 대한 정보를 추가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433ac17d-3a9b-42c2-b7ec-4eac217cbb60",
   "metadata": {},
   "source": [
    "### Output Gate\n",
    "![output gate](figures/rnn/14_output_gate.jpg)\n",
    "- 이전 time step의 hidden state와 현재 time step의 입력데이터, 현재 step의 입력이 반영된 Cell state를 이용해 출력 결과를 계산한다.\n",
    "-  **Output gate의 계산 결과는 다음 step에 hidden state(단기기억)로 전달된다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c487433-a5bd-4754-aecc-587147430e05",
   "metadata": {},
   "source": [
    "<Image 참조> https://www.pluralsight.com/guides/introduction-to-lstm-units-in-rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c3387a-4990-45e7-81be-ce555a7ea692",
   "metadata": {},
   "source": [
    "## Pytorch LSTM layer\n",
    "\n",
    "- [nn.LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\n",
    "    - **파라미터**\n",
    "        - input_size: 입력 데이터의 shape\n",
    "        - hidden_size: Layer의 Hidden size\n",
    "        - num_layers: 몇층으로 Layer을 쌓을지 개수\n",
    "        - batch_first: True - (batch, seqence len, ..) False - (sequence len, batch, ..). Default: False\n",
    "        - dropout: Dropout rate 비율\n",
    "        - bidirectional:  양방향 적용 여부. Default: False\n",
    "     \n",
    "### 추론시 Input tensor 구조\n",
    "- Input_data, (Hidden_state, Cell_state)\n",
    "- Input_data의 shape\n",
    "    - **(sequence_length, batch_size, input_feature_shape)**\n",
    "- (Hidden_state, Cell_state)는 생략시 0 입력된다.\n",
    "    - Hidden_state의 shape\n",
    "        - **(D * layer수, batch_size, hidden_size)**\n",
    "        - D: 양방향(bidirectional) 이면 2 아니면 1\n",
    "    - Cell_state의 shape\n",
    "        - **(D * layer수, batch_size, hidden_size)**\n",
    "        - D: 양방향(bidirectional) 이면 2 아니면 1\n",
    "### Output tentor 구조\n",
    "- Output_data, (Hidden_state, Cell_state)\n",
    "  \n",
    "#### Output_data의 shape\n",
    "- 모든 timestep의 출력결과를 묶어서 반환\n",
    "- **(sequence length, batch_size, D * hidden_size)**\n",
    "#### Hidden_state의 shape\n",
    "- 마지막 timestep의 출력결과\n",
    "- **(D * layer수, batch_size, hidden_size)**\n",
    "- D: 양방향(bidirectional) 이면 2 아니면 1\n",
    "#### Cell_state의 shape\n",
    "- cell state(장기기억) 값\n",
    "- **(D * layer수, batch_size, hidden_size)**\n",
    "- D: 양방향(bidirectional) 이면 2 아니면 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e9c4e11-9932-4e9b-a0bc-13733a4891f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_data = torch.randn(30, 100, 4)\n",
    "# batch_first: False - (30: seq_len, 100: batch_size, 4: feature 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48123082-fc82-40bb-b514-95131fbc4dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'> 2\n",
      "<class 'torch.Tensor'> <class 'tuple'>\n",
      "out.shape: torch.Size([30, 100, 256])\n",
      "hidden.shape: torch.Size([1, 100, 256])\n",
      "cell.shape: torch.Size([1, 100, 256])\n"
     ]
    }
   ],
   "source": [
    "# 단방향, layer 1개\n",
    "lstm1 = nn.LSTM(\n",
    "    input_size=4,       # feature 수\n",
    "    hidden_size=256,    # Unit/Node 개수\n",
    "    # bidirectional=False,   # 단방향(default)\n",
    "    # num_layers=1\n",
    ") # 레이어 한 개를 만든 것.\n",
    "out = lstm1(input_data) # input_data, (hidden, cell) hidden, cell을 생략하면 둘 다 0이 들어간다. \n",
    "print(type(out), len(out))\n",
    "print(type(out[0]),type(out[1]))\n",
    "# output_data, (hidden, cell)\n",
    "# output_data: timestep별 hidden state를 모아서 반환\n",
    "# (hidden, cell): 마지막 time step에 장기/단기 기억\n",
    "\n",
    "out1, (hidden1, cell1) = lstm1(input_data)\n",
    "print(f\"out.shape: {out1.shape}\")          # [30: seq_len, 100: batch, 256: hidden_size]\n",
    "print(f\"hidden.shape: {hidden1.shape}\")    # [1: seq_len, 100, 256]\n",
    "print(f\"cell.shape: {cell1.shape}\")        # [1: seq_len, 100, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e013b2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape: torch.Size([30, 100, 512])\n",
      "hidden.shape: torch.Size([2, 100, 256])\n",
      "cell.shape: torch.Size([2, 100, 256])\n"
     ]
    }
   ],
   "source": [
    "# 양방향, layer 1개\n",
    "lstm2 = nn.LSTM(\n",
    "    input_size=4,       # feature 수\n",
    "    hidden_size=256,    # Unit/Node 개수\n",
    "    bidirectional=True,   # 양방향\n",
    "    # num_layers=1\n",
    ") # 레이어 한 개를 만든 것.\n",
    "\n",
    "out2, (hidden2, cell2) = lstm2(input_data)\n",
    "print(f\"out.shape: {out2.shape}\")          # [30, 100, 512: 순방향과 역방향 concat]\n",
    "print(f\"hidden.shape: {hidden2.shape}\")    # [2: 순방향/역방향, 100, 256]\n",
    "print(f\"cell.shape: {cell2.shape}\")        # [2: 순방향/역방향, 100, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe587e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape: torch.Size([30, 100, 512])\n",
      "hidden.shape: torch.Size([6, 100, 256])\n",
      "cell.shape: torch.Size([6, 100, 256])\n"
     ]
    }
   ],
   "source": [
    "# 양방향, layer 2개\n",
    "lstm3 = nn.LSTM(\n",
    "    input_size=4,       # feature 수\n",
    "    hidden_size=256,    # Unit/Node 개수\n",
    "    bidirectional=True,   # 양방향\n",
    "    num_layers=3\n",
    ") # 레이어 한 개를 만든 것.\n",
    "\n",
    "out3, (hidden3, cell3) = lstm3(input_data)\n",
    "print(f\"out.shape: {out3.shape}\")          # [30, 100, 512: 순방향과 역방향 concat]\n",
    "print(f\"hidden.shape: {hidden3.shape}\")    # [6: 순방향/역방향(2) * 레이어 수(3), 100, 256]\n",
    "print(f\"cell.shape: {cell3.shape}\")        # [6: 순방향/역방향(2) * 레이어 수(3), 100, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aacaecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
